{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, Union\n",
    "from langchain_community.llms.sambanova import SambaStudio, Sambaverse\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.tools import ToolException\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(False)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, '..'))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "load_dotenv(os.path.join(repo_dir, '.env'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class GetTimeSchema(BaseModel):\n",
    "    \"\"\"Returns current date, current time or both.\"\"\"\n",
    "\n",
    "    kind: Optional[str] = Field(description='kind of information to retrieve \"date\", \"time\" or \"both\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition using @tool decorator\n",
    "@tool(args_schema=GetTimeSchema)\n",
    "def get_time(kind: str = 'both') -> str:\n",
    "    \"\"\"Returns current date, current time or both.\n",
    "\n",
    "    Args:\n",
    "        kind: date, time or both\n",
    "    \"\"\"\n",
    "    if kind == 'date':\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        return f'Current date: {date}'\n",
    "    elif kind == 'time':\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current time: {time}'\n",
    "    else:\n",
    "        date = datetime.now().strftime('%d/%m/%Y')\n",
    "        time = datetime.now().strftime('%H:%M:%S')\n",
    "        return f'Current date: {date}, Current time: {time}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current time: 10:53:26'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.invoke({'kind': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'GetTimeSchema',\n",
       " 'description': 'Returns current date, current time or both.',\n",
       " 'type': 'object',\n",
       " 'properties': {'kind': {'title': 'Kind',\n",
       "   'description': 'kind of information to retrieve \"date\", \"time\" or \"both\"',\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized error handling tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class CalculatorSchema(BaseModel):\n",
    "    \"\"\"allow calculation of only basic operations: + - * and /\n",
    "    with a string input expression\"\"\"\n",
    "\n",
    "    expression: str = Field(..., description=\"expression to calculate, example '12 * 3'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to use in the tool\n",
    "def calculator(expression: str) -> Union[str, int, float]:\n",
    "    \"\"\"\n",
    "    allow calculation of basic operations\n",
    "    with a string input expression\n",
    "    Args:\n",
    "        expression: expression to calculate\n",
    "    \"\"\"\n",
    "    ops = {\n",
    "        '+': operator.add,\n",
    "        '-': operator.sub,\n",
    "        '*': operator.mul,\n",
    "        'x': operator.mul,\n",
    "        'X': operator.mul,\n",
    "        'รท': operator.truediv,\n",
    "        '/': operator.truediv,\n",
    "    }\n",
    "    tokens = re.findall(r'\\d+\\.?\\d*|\\+|\\-|\\*|\\/|รท|x|X', expression)\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        raise ToolException(\n",
    "            f\"Invalid expression '{expression}', should only contain one of the following operators + - * and /\"\n",
    "        )\n",
    "\n",
    "    current_value = float(tokens.pop(0))\n",
    "\n",
    "    while len(tokens) > 0:\n",
    "        # The next token should be an operator\n",
    "        op = tokens.pop(0)\n",
    "\n",
    "        # The next token should be a number\n",
    "        if len(tokens) == 0:\n",
    "            raise ToolException(f\"Incomplete expression '{expression}'\")\n",
    "        try:\n",
    "            next_value = float(tokens.pop(0))\n",
    "\n",
    "        except ValueError:\n",
    "            raise ToolException('Invalid number format')\n",
    "\n",
    "        except:\n",
    "            raise ToolException('Invalid operation')\n",
    "\n",
    "        # check division by 0\n",
    "        if op in ['/', 'รท'] and next_value == 0:\n",
    "            raise ToolException('cannot divide by 0')\n",
    "\n",
    "        current_value = ops[op](current_value, next_value)\n",
    "\n",
    "    result = current_value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# tool error handler\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return f'The following errors occurred during Calculator tool execution: `{error.args}`'\n",
    "\n",
    "\n",
    "# tool definition\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=calculator,\n",
    "    args_schema=CalculatorSchema,\n",
    "    handle_tool_error=_handle_error,  # True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following errors occurred during Calculator tool execution: `('cannot divide by 0',)`\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke('7 / 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'CalculatorSchema',\n",
       " 'description': 'allow calculation of only basic operations: + - * and /\\nwith a string input expression',\n",
       " 'type': 'object',\n",
       " 'properties': {'expression': {'title': 'Expression',\n",
       "   'description': \"expression to calculate, example '12 * 3'\",\n",
       "   'type': 'string'}},\n",
       " 'required': ['expression']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class ReplSchema(BaseModel):\n",
    "    \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.\"\n",
    "\n",
    "    command: str = Field(..., description='python code to execute to evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool definition\n",
    "python_repl = PythonREPL()\n",
    "python_repl = Tool(\n",
    "    name='python_repl',\n",
    "    description='A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.',\n",
    "    func=python_repl.run,\n",
    "    args_schema=ReplSchema,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.invoke({'command': 'for i in range(0,5):\\n\\tprint(i)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ReplSchema',\n",
       " 'description': 'A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.',\n",
       " 'type': 'object',\n",
       " 'properties': {'command': {'title': 'Command',\n",
       "   'description': 'python code to execute to evaluate',\n",
       "   'type': 'string'}},\n",
       " 'required': ['command']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_repl.get_input_schema().schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This tools is a demonstration of how to implement an SQL query tool, for this you will need to have a fine tunned sql model, in this exaample we provide one available in Sambaverse, for fine tuning your own sql model go to [fine_tuning_sql kit](../../fine_tuning_sql/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n",
      "[(1, 'Rock'), (2, 'Jazz'), (3, 'Metal'), (4, 'Alternative & Punk'), (5, 'Rock And Roll'), (6, 'Blues'), (7, 'Latin'), (8, 'Reggae'), (9, 'Pop'), (10, 'Soundtrack'), (11, 'Bossa Nova'), (12, 'Easy Listening'), (13, 'Heavy Metal'), (14, 'R&B/Soul'), (15, 'Electronica/Dance'), (16, 'World'), (17, 'Hip Hop/Rap'), (18, 'Science Fiction'), (19, 'TV Shows'), (20, 'Sci Fi & Fantasy'), (21, 'Drama'), (22, 'Comedy'), (23, 'Alternative'), (24, 'Classical'), (25, 'Opera')]\n"
     ]
    }
   ],
   "source": [
    "# example sql query call\n",
    "db_path = os.path.join(kit_dir, 'data/chinook.db')\n",
    "db_uri = f'sqlite:///{db_path}'\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "print(db.get_usable_table_names())\n",
    "print(db.run('SELECT * FROM genres;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema\n",
    "class QueryDBSchema(BaseModel):\n",
    "    \"A database querying tool. Use this to generate sql querys and retrieve the results from a database. Input should be a natural language question to the db.\"\n",
    "\n",
    "    query: str = Field(..., description='python code to execute to evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=QueryDBSchema)\n",
    "def query_db(query):\n",
    "    \"\"\"A database querying tool. Use this to generate sql querys and retrieve the results from a database. Input should be a natural language question to the db.\"\"\"\n",
    "\n",
    "    fine_tunned_sql_llm = 'nsql-llama-2-7b'\n",
    "    llm = Sambaverse(\n",
    "        sambaverse_model_name='Numbers Station/nsql-llama-2-7b',\n",
    "        model_kwargs={'max_tokens_to_generate': 256, 'select_expert': fine_tunned_sql_llm, 'process_prompt': True},\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        '{table_info}\\n\\n-- Using valid SQLite, answer the following questions for the tables provided above.\\n\\n-- {input} {top_k}\\n\\nSELECT'\n",
    "    )\n",
    "    write_query = create_sql_query_chain(llm, db, prompt=prompt)\n",
    "\n",
    "    # print(write_query.invoke({'question': query}))\n",
    "\n",
    "    execute_query = QuerySQLDataBaseTool(db=db)\n",
    "    sql_chain = write_query | execute_query\n",
    "\n",
    "    return sql_chain.invoke({'question': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(25,)]'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db.invoke({'query': 'How many genres of music are in the chinook db'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default response tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'ConversationalResponse',\n",
       " 'description': 'Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.',\n",
       " 'type': 'object',\n",
       " 'properties': {'response': {'title': 'Response',\n",
       "   'description': 'Conversational response to the user.',\n",
       "   'type': 'string'}},\n",
       " 'required': ['response']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool schema\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\"\n",
    "\n",
    "    response: str = Field(..., description='Conversational response to the user.')\n",
    "\n",
    "\n",
    "ConversationalResponse.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools_schemas(tools: Union[Tool, list] = None, default: Union[Tool, BaseModel] = None):\n",
    "    if tools is None:\n",
    "        pass\n",
    "    elif isinstance(tools, Tool):\n",
    "        tools = [tools]\n",
    "    tools_schemas = []\n",
    "\n",
    "    for tool in tools:\n",
    "        tool_schema = tool.get_input_schema().schema()\n",
    "        schema = {'name': tool.name, 'description': tool_schema['description'], 'properties': tool_schema['properties']}\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    if default is not None:\n",
    "        if isinstance(default, Tool):\n",
    "            tool_schema = default.get_input_schema().schema()\n",
    "        else:\n",
    "            tool_schema = default.schema()\n",
    "        schema = {\n",
    "            'name': tool_schema['title'],\n",
    "            'description': tool_schema['description'],\n",
    "            'properties': tool_schema['properties'],\n",
    "        }\n",
    "        if 'required' in schema:\n",
    "            schema['required'] = tool_schema['required']\n",
    "        tools_schemas.append(schema)\n",
    "\n",
    "    return tools_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_time, calculator, python_repl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '  \"name\": \"get_time\",\\n'\n",
      " '  \"description\": \"Returns current date, current time or both.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"kind\": {\\n'\n",
      " '      \"title\": \"Kind\",\\n'\n",
      " '      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" '\n",
      " 'or \\\\\"both\\\\\"\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"calculator\",\\n'\n",
      " '  \"description\": \"allow calculation of only basic operations: + - * and '\n",
      " '/\\\\nwith a string input expression\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"expression\": {\\n'\n",
      " '      \"title\": \"Expression\",\\n'\n",
      " '      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"python_repl\",\\n'\n",
      " '  \"description\": \"A Python shell. Use this to execute python commands. Input '\n",
      " 'should be a valid python commands and expressions. If you want to see the '\n",
      " 'output of a value, you should print it out with `print(...), if you need a '\n",
      " 'specific module you should import it`.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"command\": {\\n'\n",
      " '      \"title\": \"Command\",\\n'\n",
      " '      \"description\": \"python code to execute to evaluate\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}\\n'\n",
      " '{\\n'\n",
      " '  \"name\": \"ConversationalResponse\",\\n'\n",
      " '  \"description\": \"Respond conversationally only if no other tools should be '\n",
      " 'called for a given query, or if you have a final answer.\",\\n'\n",
      " '  \"properties\": {\\n'\n",
      " '    \"response\": {\\n'\n",
      " '      \"title\": \"Response\",\\n'\n",
      " '      \"description\": \"Conversational response to the user.\",\\n'\n",
      " '      \"type\": \"string\"\\n'\n",
      " '    }\\n'\n",
      " '  }\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "tools_schemas = get_tools_schemas(tools, default=ConversationalResponse)\n",
    "tools_schemas = '\\n'.join([json.dumps(tool, indent=2) for tool in tools_schemas])\n",
    "pprint(tools_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Sambaverse(\n",
    "    sambaverse_model_name='Meta/Meta-Llama-3-70B-Instruct',\n",
    "    model_kwargs={\n",
    "        'max_tokens_to_generate': 2048,\n",
    "        'select_expert': 'Meta-Llama-3-70B-Instruct',\n",
    "        'process_prompt': True,\n",
    "        'temperature': 0.01,\n",
    "    },\n",
    ")\n",
    "\n",
    "# llm= SambaStudio(\n",
    "#     streaming=True,\n",
    "#     model_kwargs={\n",
    "#             \"max_tokens_to_generate\": 2048,\n",
    "#             \"select_expert\": \"Meta-Llama-3-70B-Instruct\",\n",
    "#             \"process_prompt\": False\n",
    "#         }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_map = {\n",
    "    'get_time': get_time,\n",
    "    'calculator': calculator,\n",
    "    'python_repl': python_repl,\n",
    "}\n",
    "\n",
    "\n",
    "def execute(tools):\n",
    "    tool_msg = \"Tool '{name}'response: {response}\"\n",
    "    tools_msgs = []\n",
    "    if len(tools) == 1 and tools[0]['tool'].lower() == 'conversationalresponse':\n",
    "        final_answer = True\n",
    "        return final_answer, tools[0]['tool_input']['response']\n",
    "    for tool in tools:\n",
    "        final_answer = False\n",
    "        if tool['tool'].lower() != 'conversationalresponse':\n",
    "            response = tools_map[tool['tool'].lower()](tool['tool_input'])\n",
    "            tools_msgs.append(tool_msg.format(name=tool['tool'], response=str(response)))\n",
    "    return final_answer, tools_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonFinder(input_string):\n",
    "    json_pattern = re.compile(r'(\\{.*\\}|\\[.*\\])', re.DOTALL)\n",
    "    # Find the first JSON structure in the string\n",
    "    json_match = json_pattern.search(input_string)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        try:\n",
    "            json.loads(json_str)\n",
    "        except:\n",
    "            json_correction_prompt = \"\"\"|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a json format corrector tool<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "            fix the following json file: {json} \n",
    "            <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "            fixed json: \"\"\"\n",
    "            json_correction_prompt_template = PromptTemplate.from_template(json_correction_prompt)\n",
    "            json_correction_chain = json_correction_prompt_template | llm\n",
    "            json_str = json_correction_chain.invoke(json_str)\n",
    "    else:\n",
    "        # implement here not finding json format parsing to json or error rising\n",
    "        json_str = None\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_function_calling_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "```json\n",
    "[{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}]\n",
    "```\n",
    "\n",
    "Think step by step\n",
    "Do not call a tool if the input depends on another tool output you dont have yet\n",
    "Do not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "User: {usr_msg} \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "Assistant:\"\"\"\n",
    "# You must wait to have a tools output before generating a final response, or calling other tools\n",
    "function_calling_prompt_template = PromptTemplate.from_template(example_function_calling_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parsing_chain = RunnableLambda(jsonFinder) | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = {\n",
    "    'tools': lambda x: tools_schemas,\n",
    "    'usr_msg': RunnablePassthrough(),\n",
    "} | function_calling_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_fc_chain = prompt_template | llm | json_parsing_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'ConversationalResponse', 'tool_input': {'response': 'Hi! How can I assist you today?'}}]\n",
      "Hi! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = 'hi'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'get_time', 'tool_input': {'kind': 'time'}}]\n",
      "[\"Tool 'get_time'response: Current time: 11:34:10\"]\n"
     ]
    }
   ],
   "source": [
    "query = 'it is time to go to sleep?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'calculator', 'tool_input': {'expression': '347 / 60'}}]\n",
      "[\"Tool 'calculator'response: 5.783333333333333\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgep/Documents/ask_public_own/fcenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "query = 'whats is 347 min in hours and minutes?'\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "print(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print('saippuakivikauppias' \"\n",
      "                            \"=='saippuakivikauppias'[::-1])\"}}]\n",
      "[\"Tool 'python_repl'response: True\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"is this word is a palindrome? 'saippuakivikauppias'\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool': 'python_repl',\n",
      "  'tool_input': {'command': \"print(sorted(['screwdriver', 'pliers', \"\n",
      "                            \"'hammer']))\"}}]\n",
      "[\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\"\n",
    "response_tools = default_fc_chain.invoke(query)\n",
    "pprint(response_tools)\n",
    "final_answer, response_tools = execute(response_tools)\n",
    "print(response_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calling_system_prompt = \"\"\"you are an helpful assistant and you have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\n",
    "\n",
    "```json\n",
    "[{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}]\n",
    "```\n",
    "\n",
    "Think step by step\n",
    "Do not call a tool if the input depends on another tool output you dont have yet\n",
    "Do not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['tools'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tools'], template='you are an helpful assistant and you have access to the following tools:\\n\\n{tools}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output you dont have yet\\nDo not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\\n\\n'))])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calling_chat_template = ChatPromptTemplate.from_messages([('system', function_calling_system_prompt)])\n",
    "function_calling_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msgs_to_llama3_str(msgs: list):\n",
    "    formatted_msgs = []\n",
    "    for msg in msgs:\n",
    "        if msg.type == 'system':\n",
    "            sys_placeholder = '<|begin_of_text|><|start_header_id|>system<|end_header_id|>system<|end_header_id|> {msg}'\n",
    "            formatted_msgs.append(sys_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'human':\n",
    "            human_placeholder = '<|eot_id|><|start_header_id|>user<|end_header_id|>\\nUser: {msg} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant:'\n",
    "            formatted_msgs.append(human_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'ai':\n",
    "            assistant_placeholder = '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant: {msg}'\n",
    "            formatted_msgs.append(assistant_placeholder.format(msg=msg.content))\n",
    "        elif msg.type == 'tool':\n",
    "            tool_placeholder = '<|eot_id|><|start_header_id|>tools<|end_header_id|>\\n{msg} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\nAssistant:'\n",
    "            formatted_msgs.append(tool_placeholder.format(msg=msg.content))\n",
    "    return '\\n'.join(formatted_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_call_llm(query, max_it=5, debug=False):\n",
    "    history = function_calling_chat_template.format_prompt(tools=tools_schemas).to_messages()\n",
    "    history.append(HumanMessage(query))\n",
    "    tool_call_id = 0\n",
    "\n",
    "    for i in range(max_it):\n",
    "        prompt = msgs_to_llama3_str(history)\n",
    "        llm_response = llm.invoke(prompt)\n",
    "        parsed_tools_llm_response = json_parsing_chain.invoke(llm_response)\n",
    "        history.append(AIMessage(llm_response))\n",
    "        final_answer, tools_msgs = execute(parsed_tools_llm_response)\n",
    "        if final_answer:\n",
    "            final_response = tools_msgs\n",
    "            if debug:\n",
    "                pprint(history)\n",
    "            return final_response\n",
    "        else:\n",
    "            history.append(ToolMessage('\\n'.join(tools_msgs), tool_call_id=tool_call_id))\n",
    "            tool_call_id += 1\n",
    "\n",
    "    raise Exception('not a final response yet', json.dumps(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression \",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to execute to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output you dont have yet\\nDo not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\\n\\n'),\n",
      " HumanMessage(content='what time is it?'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"both\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current date: 17/06/2024, Current time: 11:36:42\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"The current date and time is 17/06/2024, 11:36:42.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('what time is it?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date and time is 17/06/2024, 11:36:42.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression \",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to execute to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output you dont have yet\\nDo not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\\n\\n'),\n",
      " HumanMessage(content='it is time to go to sleep, how many hours last to 10pm?'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"get_time\",\\n  \"tool_input\": {\\n    \"kind\": \"time\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'get_time'response: Current time: 11:37:00\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"22 - \" + \"11 + (37 / 60)\"\\n  }\\n}]\\n'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 0.8\", tool_call_id='1'),\n",
      " AIMessage(content='Assistant: [{\\n  \"tool\": \"calculator\",\\n  \"tool_input\": {\\n    \"expression\": \"10 - 0.8\"\\n  }\\n}]\\n'),\n",
      " ToolMessage(content=\"Tool 'calculator'response: 9.2\", tool_call_id='2'),\n",
      " AIMessage(content='Assistant: [{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"There are 9 hours and 12 minutes left until 10pm.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm('it is time to go to sleep, how many hours last to 10pm?', max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 9 hours and 12 minutes left until 10pm.'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression \",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to execute to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output you dont have yet\\nDo not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\\n\\n'),\n",
      " HumanMessage(content=\"is this word is a palindrome? 'saippuakivikauppias'\"),\n",
      " AIMessage(content='[{\\n  \"tool\": \"python_repl\",\\n  \"tool_input\": {\\n    \"command\": \"print(\\'saippuakivikauppias\\' ==\\'saippuakivikauppias\\'[::-1])\"\\n  }\\n}]'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: True\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[{\\n  \"tool\": \"ConversationalResponse\",\\n  \"tool_input\": {\\n    \"response\": \"Yes, the word\\'saippuakivikauppias\\' is a palindrome.\"\\n  }\\n}]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\"is this word is a palindrome? 'saippuakivikauppias'\", max_it=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, the word'saippuakivikauppias' is a palindrome.\""
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='you are an helpful assistant and you have access to the following tools:\\n\\n{\\n  \"name\": \"get_time\",\\n  \"description\": \"Returns current date, current time or both.\",\\n  \"properties\": {\\n    \"kind\": {\\n      \"title\": \"Kind\",\\n      \"description\": \"kind of information to retrieve \\\\\"date\\\\\", \\\\\"time\\\\\" or \\\\\"both\\\\\"\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"calculator\",\\n  \"description\": \"allow calculation of only basic operations: + - * and /\\\\nwith a string input expression \",\\n  \"properties\": {\\n    \"expression\": {\\n      \"title\": \"Expression\",\\n      \"description\": \"expression to calculate, example \\'12 * 3\\'\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"python_repl\",\\n  \"description\": \"A Python shell. Use this to execute python commands. Input should be a valid python commands and expressions. If you want to see the output of a value, you should print it out with `print(...), if you need a specific module you should import it`.\",\\n  \"properties\": {\\n    \"command\": {\\n      \"title\": \"Command\",\\n      \"description\": \"python code to execute to evaluate\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n{\\n  \"name\": \"ConversationalResponse\",\\n  \"description\": \"Respond conversationally only if no other tools should be called for a given query, or if you have a final answer.\",\\n  \"properties\": {\\n    \"response\": {\\n      \"title\": \"Response\",\\n      \"description\": \"Conversational response to the user.\",\\n      \"type\": \"string\"\\n    }\\n  }\\n}\\n\\nYou must always select one or more of the above tools and answer with only a list of JSON objects matching the following schema:\\n\\n```json\\n[{\\n  \"tool\": <name of the selected tool>,\\n  \"tool_input\": <parameters for the selected tool, matching the tool\\'s JSON schema>\\n}]\\n```\\n\\nThink step by step\\nDo not call a tool if the input depends on another tool output you dont have yet\\nDo not try to answer until you get tools output, if you dont have an answer yet you can continue calling tools\\n\\n'),\n",
      " HumanMessage(content=\"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\"),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"python_repl\",\\n    \"tool_input\": {\\n      \"command\": \"print(sorted([\\'screwdriver\\', \\'pliers\\', \\'hammer\\']))\"\\n    }\\n  }\\n]'),\n",
      " ToolMessage(content=\"Tool 'python_repl'response: ['hammer', 'pliers', 'screwdriver']\\n\", tool_call_id='0'),\n",
      " AIMessage(content='[\\n  {\\n    \"tool\": \"ConversationalResponse\",\\n    \"tool_input\": {\\n      \"response\": \"The sorted list is: [\\'hammer\\', \\'pliers\\',\\'screwdriver\\']\"\\n    }\\n  }\\n]')]\n"
     ]
    }
   ],
   "source": [
    "response = function_call_llm(\n",
    "    \"sort this list of elements alphabetically ['screwdriver', 'pliers', 'hammer']\", max_it=5, debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sorted list is: ['hammer', 'pliers','screwdriver']\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
