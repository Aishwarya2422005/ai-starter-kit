{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import yaml\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from dotenv import load_dotenv\n",
    "import tarfile\n",
    "load_dotenv(os.path.join(repo_dir,\".env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch image ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "=====================================================\n",
      "Name                : CLIP\n",
      "ID                  : 6c14325a-1be7-4e48-b38f-19b33745fc3b\n",
      "Playground          : False\n",
      "Prediction Input    : text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!snapi app list | grep CLIP -A 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predinction csv\n",
    "def generate_csv(dataset_dir):\n",
    "    image_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                image_path = os.path.relpath(os.path.join(root, file), dataset_dir)\n",
    "                image_paths.append(image_path)\n",
    "\n",
    "    df = pd.DataFrame({'image_path': image_paths, 'description': '', 'subset': '', 'metadata': ''})\n",
    "    df.to_csv(os.path.join(dataset_dir,'predictions.csv'), index=False)\n",
    "\n",
    "# Specify the directory containing your dataset\n",
    "dataset_directory = '../data/images'\n",
    "generate_csv(dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = load_config(os.path.join(kit_dir,'config.yaml'))\n",
    "\n",
    "PENDING_RDU_JOB_STATUS = 'PENDING_RDU'\n",
    "SUCCESS_JOB_STATUS = 'EXIT_WITH_0'\n",
    "FAILED_JOB_STATUS = 'FAILED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchClipProcessor():\n",
    "    \n",
    "    def __init__(self, config) -> None:\n",
    "        self.headers = {\n",
    "            'content-type': 'application/json',\n",
    "            'key': os.getenv('SAMBASTUDIO_KEY'),\n",
    "        }\n",
    "        self.datasets_path = f\".{config['clip']['datasets']['datasets_path']}\"\n",
    "        self.dataset_id = None\n",
    "        self.dataset_name = config['clip']['datasets']['dataset_name']\n",
    "        self.dataset_description = config['clip']['datasets']['dataset_description']\n",
    "        self.dataset_source_type = config['clip']['datasets']['dataset_source_type']\n",
    "        self.dataset_source_file = f\".{config['clip']['datasets']['dataset_source_file']}\"\n",
    "        \n",
    "        self.clip_app_id = config['clip']['apps']['clip_app_id']\n",
    "        self.application_field = config['clip']['apps']['application_field']\n",
    "        \n",
    "        self.base_url = config['clip']['urls']['base_url']\n",
    "        self.datasets_url = config['clip']['urls']['datasets_url'] \n",
    "        self.projects_url = config['clip']['urls']['projects_url'] \n",
    "        self.jobs_url = config['clip']['urls']['jobs_url'] \n",
    "        self.download_results_url = config['clip']['urls']['download_results_url'] \n",
    "    \n",
    "        self.project_name = config['clip']['projects']['project_name']\n",
    "        self.project_description = config['clip']['projects']['project_description']\n",
    "        self.project_id=None\n",
    "        \n",
    "        self.job_name = config['clip']['jobs']['job_name']\n",
    "        self.job_task = config['clip']['jobs']['job_task']\n",
    "        self.job_type = config['clip']['jobs']['job_type']\n",
    "        self.job_description = config['clip']['jobs']['job_description']\n",
    "        self.model_checkpoint = config['clip']['jobs']['model_checkpoint']\n",
    "        \n",
    "        self.output_path = config['clip']['output']['output_path']\n",
    "        \n",
    "        \n",
    "    def _get_call(self, url, params = None, success_message = None):\n",
    "        response = requests.get(url, params=params, headers=self.headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            logging.info('GET request successful!')\n",
    "            logging.info(success_message)\n",
    "            logging.debug(f'Response: {response.text}')\n",
    "        else:\n",
    "            logging.error(f'GET request failed with status code: {response.status_code}')\n",
    "            logging.error(f'Error message: {response.text}')\n",
    "        return response\n",
    "\n",
    "    def _post_call(self, url, params, success_message = None):\n",
    "        response = requests.post(url, json=params, headers=self.headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            logging.info('POST request successful!')\n",
    "            logging.info(success_message)\n",
    "            logging.debug(f'Response: {response.text}')\n",
    "        else:\n",
    "            logging.error(f'POST request failed with status code: {response.status_code}')\n",
    "            raise Exception(f'Error message: {response.text}')\n",
    "        return response\n",
    "    \n",
    "    def _delete_call(self, url):\n",
    "        response = requests.delete(url, headers=self.headers)    \n",
    "        if response.status_code == 200:\n",
    "            logging.info(f'Dataset {self.dataset_name} deleted successfully.')\n",
    "            logging.debug(f'Response: {response.text}')\n",
    "        else:\n",
    "            logging.error(f'Failed to delete the resource. Status code: {response.status_code}')\n",
    "            raise Exception(f'Error message: {response.text}')    \n",
    "        return response\n",
    "    def _generate_csv(self, dataset_dir):\n",
    "        image_paths = []\n",
    "        for root, dirs, files in os.walk(dataset_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "                    image_path = os.path.relpath(os.path.join(root, file), dataset_dir)\n",
    "                    image_paths.append(image_path)\n",
    "\n",
    "        df = pd.DataFrame({'image_path': image_paths, 'description': '', 'subset': '', 'metadata': ''})\n",
    "        df.to_csv(os.path.join(dataset_dir,'predictions.csv'), index=False)\n",
    "\n",
    "    def _get_df_output(self, response_content: str) -> DataFrame:\n",
    "        compressed_bytes = io.BytesIO(response_content)\n",
    "        \n",
    "        with tarfile.open(fileobj=compressed_bytes, mode=\"r:gz\") as tar:\n",
    "            output_tar_member = tar.getmember(self.output_path)\n",
    "            output_file = tar.extractfile(output_tar_member)\n",
    "            output_df = pd.read_json(io.BytesIO(output_file.read()), lines=True)       \n",
    "        return output_df\n",
    "\n",
    "    def search_dataset(self, dataset_name):\n",
    "        url = self.base_url + self.datasets_url + '/search'\n",
    "        params = {\n",
    "            'dataset_name': dataset_name\n",
    "        }\n",
    "        response = self._get_call(url, params, f'Dataset {dataset_name} found in SambaStudio')\n",
    "        parsed_reponse = json.loads(response.text)\n",
    "        return parsed_reponse['data']['dataset_id']\n",
    "\n",
    "    def delete_dataset(self, dataset_name):\n",
    "        dataset_id = self.search_dataset(dataset_name)\n",
    "        url = self.base_url + self.datasets_url + '/' + dataset_id\n",
    "        response = self._delete_call(url)\n",
    "        logging.info(response.text)\n",
    "        \n",
    "        \n",
    "    def create_dataset(self, path):\n",
    "        # create clip directory and source.json file\n",
    "        \n",
    "        dataset_name = f'{self.dataset_name}_{int(time.time())}'\n",
    "            \n",
    "        clip_directory = os.path.join(self.datasets_path, dataset_name)\n",
    "        \n",
    "        if not os.path.isdir(self.datasets_path):\n",
    "            os.mkdir(self.datasets_path) \n",
    "            \n",
    "        if not os.path.isdir(clip_directory):\n",
    "            logging.info(f'Datasets path: {clip_directory} wan \\'t found')\n",
    "            \n",
    "            source_file_data = {\n",
    "                \"source_path\": clip_directory\n",
    "            }\n",
    "            \n",
    "            with open(self.dataset_source_file, 'w') as json_file:\n",
    "                json.dump(source_file_data, json_file)\n",
    "\n",
    "        shutil.copytree(path, clip_directory)\n",
    "        \n",
    "        self._generate_csv(clip_directory)\n",
    "        \n",
    "        # create dataset\n",
    "        command = f'echo yes | snapi dataset add \\\n",
    "            --dataset-name {dataset_name} \\\n",
    "            --job_type {self.job_type} \\\n",
    "            --apps {self.clip_app_id} \\\n",
    "            --source_type {self.dataset_source_type} \\\n",
    "            --source_file {self.dataset_source_file} \\\n",
    "            --application_field {self.application_field} \\\n",
    "            --description \"{self.dataset_description}\"'\n",
    "        \n",
    "        os.system(command)\n",
    "        logging.info(f'Creating dataset: {dataset_name}')\n",
    "        \n",
    "        return dataset_name\n",
    "         \n",
    "    def check_dataset_creation_progress(self, dataset_name):\n",
    "        url = self.base_url + self.datasets_url + '/' + dataset_name\n",
    "        response = self._get_call(url)\n",
    "        if response.json()[\"data\"][\"status\"]==\"Available\": \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    def create_load_project(self):\n",
    "\n",
    "        url = self.base_url + self.projects_url + '/' + self.project_name\n",
    "\n",
    "        response = self._get_call(url, success_message=f'Project {self.project_name} found in SambaStudio')\n",
    "        not_found_error_message = f\"{self.project_name} not found\"\n",
    "\n",
    "        if not_found_error_message in response.text:\n",
    "            \n",
    "            logging.info(f'Project {self.project_name} wasn\\'t found in SambaStudio')\n",
    "            \n",
    "            url = self.base_url + self.projects_url\n",
    "\n",
    "            params = {\n",
    "                'project_name': self.project_name,\n",
    "                'description': self.project_description\n",
    "            }\n",
    "\n",
    "            response = self._post_call(url, params, success_message=f'Project {self.project_name} created!')\n",
    "\n",
    "        parsed_reponse = json.loads(response.text)\n",
    "        self.project_id = parsed_reponse['data']['project_id']\n",
    "        return self.project_id\n",
    "    \n",
    "    def run_job(self, dataset_name):\n",
    "        \n",
    "        url = self.base_url + self.projects_url + self.jobs_url.format(project_id=self.project_id)\n",
    "        \n",
    "        params = {\n",
    "            'task': self.job_task,\n",
    "            'job_type': self.job_type,\n",
    "            'job_name': f'{self.job_name}_{int(time.time())}',\n",
    "            'project': self.project_id,\n",
    "            'model_checkpoint': self.model_checkpoint,\n",
    "            'description': self.job_description,\n",
    "            'dataset': dataset_name,\n",
    "        }\n",
    "\n",
    "        response = self._post_call(url, params, success_message='Job running')\n",
    "        parsed_reponse = json.loads(response.text)\n",
    "        job_id = parsed_reponse['data']['job_id']\n",
    "        \n",
    "        return job_id\n",
    "    \n",
    "    def check_job_progress(self, job_id):\n",
    "        \"\"\"Check job progress of a given job.\n",
    "\n",
    "        Args:\n",
    "            job_id (str): The id of the job to check.\n",
    "            \n",
    "        Returns:\n",
    "            bool: True when the job is finished.\n",
    "        \"\"\"\n",
    "\n",
    "        url = self.base_url + self.projects_url + self.jobs_url.format(project_id=self.project_id) + '/' + job_id\n",
    "\n",
    "        status = PENDING_RDU_JOB_STATUS\n",
    "        while status != SUCCESS_JOB_STATUS:\n",
    "            response = self._get_call(url, success_message='Still waiting for job to finish')\n",
    "            parsed_reponse = json.loads(response.text)   \n",
    "            status = parsed_reponse['data']['status']\n",
    "            logging.info(f'Job status: {status}')\n",
    "            if status == SUCCESS_JOB_STATUS:\n",
    "                logging.info('Job finished!')\n",
    "                break\n",
    "            elif status == FAILED_JOB_STATUS:\n",
    "                logging.info('Job failed!')\n",
    "                return False\n",
    "            time.sleep(10)\n",
    "        \n",
    "        return True  \n",
    "    \n",
    "    def delete_job(self, job_id):\n",
    "        url = self.base_url +  self.projects_url + self.jobs_url.format(project_id=self.project_id) + '/' + job_id\n",
    "        response = self._delete_call(url)\n",
    "        logging.info(response.text)\n",
    "        \n",
    "    def retrieve_results(self, job_id):\n",
    "        url = self.base_url + self.projects_url + self.jobs_url.format(project_id=self.project_id) + '/' + job_id + self.download_results_url\n",
    "        response = self._get_call(url, success_message='Results downloaded!')\n",
    "        df = self._get_df_output(response.content)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = BatchClipProcessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:Project image_search_project found in SambaStudio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'edcd0f67-0f39-4775-8ba7-d76327894b3f'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.create_load_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Datasets path: ../data/datasets/images_dataset_1710352467 wan 't found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder Information:\n",
      "  - Number of Files: 41\n",
      "  - Total Size: 16.24 MB\n",
      "\n",
      "Are you sure you want to proceed? (\u001b[33myes\u001b[0m/no)\n",
      ": Uploading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating dataset: images_dataset_1710352467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset folder upload complete: ../data/datasets/images_dataset_1710352467\n",
      "Dataset added successfully.\n",
      "Time taken to upload the dataset: 49.43410301208496 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:None\n"
     ]
    }
   ],
   "source": [
    "dataset_name = clip.create_dataset(path=os.path.join(kit_dir,'data/images'))\n",
    "while not clip.check_dataset_creation_progress(dataset_name):\n",
    "    print(\"waiting for dataset available\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:Dataset images_dataset_1710352467 found in SambaStudio\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3ef23e2b-33e5-499d-bc51-339b017a9c83'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.search_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:POST request successful!\n",
      "INFO:root:Job running\n"
     ]
    }
   ],
   "source": [
    "job_id = clip.run_job(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:Still waiting for job to finish\n",
      "INFO:root:Job status: PENDING_RDU\n",
      "INFO:root:GET request successful!\n",
      "INFO:root:Still waiting for job to finish\n",
      "INFO:root:Job status: PENDING_RDU\n",
      "INFO:root:GET request successful!\n",
      "INFO:root:Still waiting for job to finish\n",
      "INFO:root:Job status: PENDING_RDU\n",
      "INFO:root:GET request successful!\n",
      "INFO:root:Still waiting for job to finish\n",
      "INFO:root:Job status: EXIT_WITH_0\n",
      "INFO:root:Job finished!\n"
     ]
    }
   ],
   "source": [
    "result = clip.check_job_progress(job_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:Results downloaded!\n"
     ]
    }
   ],
   "source": [
    "df=clip.retrieve_results(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dataset images_dataset deleted successfully.\n",
      "INFO:root:{}\n"
     ]
    }
   ],
   "source": [
    "clip.delete_job(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:GET request successful!\n",
      "INFO:root:Dataset images_dataset_1710352467 found in SambaStudio\n",
      "INFO:root:Dataset images_dataset deleted successfully.\n",
      "INFO:root:{\"detail\":\"The Dataset: 3ef23e2b-33e5-499d-bc51-339b017a9c83 was successfully marked for deletion from the Dataset Hub.\"}\n"
     ]
    }
   ],
   "source": [
    "clip.delete_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>input</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.002137135714292, 0.278615444898605, -0.159...</td>\n",
       "      <td>art/art_1.png</td>\n",
       "      <td>img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.029079457744956003, 0.12692214548587802, -0...</td>\n",
       "      <td>places/places_2.png</td>\n",
       "      <td>img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.018383597955107002, -0.15706798434257502, -...</td>\n",
       "      <td>appliances/appliances_1.png</td>\n",
       "      <td>img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.056953176856040004, 0.11261384934186901, -...</td>\n",
       "      <td>art/art_0.png</td>\n",
       "      <td>img</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.04671736434102, 0.208280116319656, -0.07212...</td>\n",
       "      <td>nature/nature_2.png</td>\n",
       "      <td>img</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         predictions  \\\n",
       "0  [-0.002137135714292, 0.278615444898605, -0.159...   \n",
       "1  [0.029079457744956003, 0.12692214548587802, -0...   \n",
       "2  [0.018383597955107002, -0.15706798434257502, -...   \n",
       "3  [-0.056953176856040004, 0.11261384934186901, -...   \n",
       "4  [0.04671736434102, 0.208280116319656, -0.07212...   \n",
       "\n",
       "                         input type  \n",
       "0                art/art_1.png  img  \n",
       "1          places/places_2.png  img  \n",
       "2  appliances/appliances_1.png  img  \n",
       "3                art/art_0.png  img  \n",
       "4          nature/nature_2.png  img  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from chromadb.api.types import is_image, is_document, Images,  Documents, EmbeddingFunction, Embeddings, Protocol\n",
    "from typing import cast, Union, TypeVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chromadb multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embeddable = Union[Documents, Images]\n",
    "D = TypeVar(\"D\", bound=Embeddable, contravariant=True)\n",
    "\n",
    "class ClipEmbbeding(EmbeddingFunction[D]):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def __call__(self, input: D) -> Embeddings:\n",
    "        embeddings: Embeddings = []\n",
    "        for item in input:     \n",
    "            if is_document(item):\n",
    "                #TODO implement SN endpoint inference\n",
    "                output = None\n",
    "            elif is_image(item):\n",
    "                image = Image.fromarray(item)\n",
    "                buffer = io.BytesIO()\n",
    "                image.save(buffer, format='PNG')\n",
    "                buffer\n",
    "                #TODO implement SN endpoint inference\n",
    "                output = None\n",
    "            embeddings.append(output[\"embedding\"])\n",
    "        return cast(Embeddings, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path=os.path.join(kit_dir,\"data\"))\n",
    "clip_embedding=ClipEmbbeding()\n",
    "try:\n",
    "    client.delete_collection(name=\"image_collection\")\n",
    "except:\n",
    "    pass\n",
    "collection=client.get_or_create_collection(name=\"image_collection\", embedding_function=clip_embedding, metadata={\"hnsw:space\": \"l2\"})\n",
    "collection.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add individual images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(folder_path):\n",
    "    images=[]\n",
    "    paths=[]\n",
    "    for root, _dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "                path=os.path.join(root, file)\n",
    "                paths.append(path)\n",
    "                image= np.array(Image.open(os.path.join(root, file)))\n",
    "                images.append(image)\n",
    "    return paths,images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "paths, images=get_images(os.path.join(kit_dir,\"data/images\"))\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    images=images,\n",
    "    metadatas=[{\"source\": path} for path in paths],\n",
    "    ids=paths,\n",
    "    uris=paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()#include=[\"uris\",\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add batch preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = list(df[\"predictions\"]) \n",
    "paths = list(df[\"input\"].apply(lambda x: os.path.join(kit_dir,'data/images',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    embeddings=embeddings,\n",
    "    metadatas=[{\"source\": path} for path in paths],\n",
    "    ids=paths,\n",
    "    uris=paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_3.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/appliances/appliances_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/appliances/appliances_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_3.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_3.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_3.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_0.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_4.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_1.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_2.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_3.png',\n",
       "  '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_4.png'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_3.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/animals/animals_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/appliances/appliances_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/appliances/appliances_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/art/art_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_3.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/food/food_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_3.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/nature/nature_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/places/places_3.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_0.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/professions/professions_4.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_1.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_2.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_3.png'},\n",
       "  {'source': '/Users/jorgep/Documents/ask_public_own/ai-starter-kit/image_search/data/images/sports/sports_4.png'}],\n",
       " 'documents': [None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None,\n",
       "  None],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()#include=[\"uris\",\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image_by_text(query,n=1):\n",
    "    result=collection.query(query_texts=[query],include=[\"uris\", \"distances\"],n_results=n)\n",
    "    return result['uris'][0], result[\"distances\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_image_by_image(path,n=5):\n",
    "    image= np.array(Image.open(path))\n",
    "    result=collection.query(query_images=[image],include=[\"uris\", \"distances\"],n_results=n)\n",
    "    return result['uris'][0], result[\"distances\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_images(image_paths, distances):\n",
    "    num_images = len(image_paths)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10*num_images, 10))\n",
    "    \n",
    "    for i, path in enumerate(image_paths):\n",
    "        img = mpimg.imread(path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Image {i+1}, d={distances[i]}')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris, distances = search_image_by_text(\"birds\")\n",
    "show_images(uris, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uris, distances = search_image_by_image(\"../download.jpeg\")\n",
    "uris.insert(0, \"../download.jpeg\")\n",
    "distances.insert(0, 0)\n",
    "show_images(uris, distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
