{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rag_eval import RAGEvaluator, RAGEvalConfig, load_pipeline, load_eval_dataframe  \n",
    "from langchain_community.llms.sambanova import SambaStudio\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = RAGEvalConfig(\"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator\n",
    "eval_llms = [SambaStudio(**conf) for conf in config.eval_llm_configs]\n",
    "eval_embeddings = HuggingFaceInstructEmbeddings(model_name=config.embedding_model_name)\n",
    "evaluator = RAGEvaluator(eval_llms, eval_embeddings, \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 1: CSV file with pre-generated answers, no context\n",
    "eval_df = pd.read_csv(\"eval_set_with_answers.csv\")\n",
    "results1 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 1:\", results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2: CSV file with pre-generated answers and context  \n",
    "eval_df = pd.read_csv(\"eval_set_with_answers_and_context.csv\")\n",
    "results2 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 2:\", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 3: CSV file without answers, generate with pipelines, no context\n",
    "eval_df = pd.read_csv(\"eval_set.csv\")\n",
    "pipelines = [load_pipeline(SambaStudio(**conf), config) for conf in config.llm_configs]  \n",
    "results3 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 3:\", results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 4: CSV file without answers, generate with pipelines, with context from vector DB\n",
    "eval_df = pd.read_csv(\"eval_set.csv\")\n",
    "pipelines = [load_pipeline(SambaStudio(**conf), config) for conf in config.llm_configs]\n",
    "results4 = evaluator.evaluate(eval_df, pipelines) \n",
    "print(\"Results 4:\", results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 5: Evaluate on HF dataset\n",
    "config.config[\"eval_dataset\"][\"hf_dataset_name\"] = \"squad_v2\"\n",
    "eval_df = load_eval_dataframe(config)\n",
    "pipelines = [load_pipeline(SambaStudio(**conf), config) for conf in config.llm_configs] \n",
    "results5 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 5:\", results5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
