{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the repo dir /Users/kwasia/Documents/Projects/ai-starter-kit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "print(f\"This is the repo dir {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwasia/.pyenv/versions/3.11.3/envs/adi-rag-eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.eval.rag_eval import (\n",
    "    RAGEvaluator,\n",
    "    RAGEvalConfig,\n",
    "    load_pipeline,\n",
    "    load_eval_dataframe,\n",
    ")\n",
    "from langchain_community.llms.sambanova import SambaStudio, Sambaverse\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = \"../../utils/eval/config.yaml\"\n",
    "config = RAGEvalConfig(config_yaml_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'eval_llm1', 'model_kwargs': {'temperature': 0.4, 'max_tokens': 1000}}\n",
      "{'sambastudio_base_url': 'https://sjc3-tsstage.sambanova.net', 'sambastudio_project_id': 'c84c37aa-05ca-4849-8a1b-9eac46bd962c', 'sambastudio_endpoint_id': '1fbb804d-c349-4897-a4d4-0b8d907d8d47', 'sambastudio_api_key': 'b874c598-ccd5-4879-a4f7-e089c6c995e3', 'model_kwargs': {'temperature': 0.4, 'max_tokens': 1000}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create evaluator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create evaluator\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m eval_llms \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSambaStudio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_llm_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_llm_configs\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m eval_embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceInstructEmbeddings(model_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_model_name)\n\u001b[1;32m      8\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m RAGEvaluator(eval_llms, eval_embeddings, config_path)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create evaluator\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Create evaluator\u001b[39;00m\n\u001b[1;32m      3\u001b[0m eval_llms \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 4\u001b[0m     SambaStudio(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_llm_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conf \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39meval_llm_configs\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m eval_embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceInstructEmbeddings(model_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_model_name)\n\u001b[1;32m      8\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m RAGEvaluator(eval_llms, eval_embeddings, config_path)\n",
      "File \u001b[0;32m~/Documents/Projects/ai-starter-kit/utils/eval/rag_eval.py:36\u001b[0m, in \u001b[0;36mRAGEvalConfig.get_llm_config\u001b[0;34m(self, llm_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_llm_config\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_config: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(llm_config)\n\u001b[0;32m---> 36\u001b[0m     llm_name \u001b[38;5;241m=\u001b[39m \u001b[43mllm_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msambastudio_base_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msambastudio_project_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllm_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_PROJECT_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: llm_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m     43\u001b[0m     }\n",
      "\u001b[0;31mKeyError\u001b[0m: 'name'"
     ]
    }
   ],
   "source": [
    "# Create evaluator\n",
    "# Create evaluator\n",
    "eval_llms = [SambaStudio(**conf) for conf in config.eval_llm_configs]\n",
    "eval_embeddings = HuggingFaceInstructEmbeddings(model_name=config.embedding_model_name)\n",
    "evaluator = RAGEvaluator(eval_llms, eval_embeddings, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 1: CSV file with pre-generated answers, no context\n",
    "eval_df = pd.read_csv(\"eval_set_with_answers.csv\")\n",
    "results1 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 1:\", results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2: CSV file with pre-generated answers and context\n",
    "eval_df = pd.read_csv(\"eval_set_with_answers_and_context.csv\")\n",
    "results2 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 2:\", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 3: CSV file without answers, generate with pipelines, no context\n",
    "eval_df = pd.read_csv(\"eval_set.csv\")\n",
    "pipelines = [\n",
    "    load_pipeline(\n",
    "        SambaStudio(\n",
    "            sambastudio_base_url=conf[\"base_url\"],\n",
    "            sambastudio_project_id=conf[\"project_id\"],\n",
    "            sambastudio_endpoint_id=conf[\"endpoint_id\"],\n",
    "            sambastudio_api_key=conf[\"api_key\"],\n",
    "            **conf[\"model_kwargs\"]\n",
    "        ),\n",
    "        config,\n",
    "    )\n",
    "    for conf in config.llm_configs\n",
    "]\n",
    "results3 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 3:\", results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 4: CSV file without answers, generate with pipelines, with context from vector DB\n",
    "eval_df = pd.read_csv(\"eval_set.csv\")\n",
    "pipelines = [\n",
    "    load_pipeline(\n",
    "        SambaStudio(\n",
    "            sambastudio_base_url=conf[\"base_url\"],\n",
    "            sambastudio_project_id=conf[\"project_id\"],\n",
    "            sambastudio_endpoint_id=conf[\"endpoint_id\"],\n",
    "            sambastudio_api_key=conf[\"api_key\"],\n",
    "            **conf[\"model_kwargs\"]\n",
    "        ),\n",
    "        config,\n",
    "    )\n",
    "    for conf in config.llm_configs\n",
    "]\n",
    "results4 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 4:\", results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 5: Evaluate on HF dataset\n",
    "config.config[\"eval_dataset\"][\"hf_dataset_name\"] = \"squad_v2\"\n",
    "eval_df = load_eval_dataframe(config)\n",
    "pipelines = [\n",
    "    load_pipeline(\n",
    "        SambaStudio(\n",
    "            sambastudio_base_url=conf[\"base_url\"],\n",
    "            sambastudio_project_id=conf[\"project_id\"],\n",
    "            sambastudio_endpoint_id=conf[\"endpoint_id\"],\n",
    "            sambastudio_api_key=conf[\"api_key\"],\n",
    "            **conf[\"model_kwargs\"]\n",
    "        ),\n",
    "        config,\n",
    "    )\n",
    "    for conf in config.llm_configs\n",
    "]\n",
    "results5 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 5:\", results5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adi-rag-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
