{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the repo dir /Users/kwasia/Documents/Projects/ai-starter-kit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "print(f\"This is the repo dir {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwasia/.pyenv/versions/3.11.3/envs/adi-rag-eval/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.eval.rag_eval import (\n",
    "    RAGEvaluator,\n",
    "    RAGEvalConfig,\n",
    "    load_pipeline,\n",
    "    load_eval_dataframe,\n",
    ")\n",
    "from langchain_community.llms.sambanova import SambaStudio, Sambaverse\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = \"../../utils/eval/config.yaml\"\n",
    "config = RAGEvalConfig(config_yaml_path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf: ('EVAL_LLAMA38B', {'name': 'EVAL_LLAMA38B', 'model_kwargs': {'select_expert': 'Meta-Llama-3-8B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512}})\n",
      "llm_name: EVAL_LLAMA38B\n",
      "llm_config: {'sambastudio_base_url': 'https://sjc3-svqa.sambanova.net', 'sambastudio_project_id': '0c027dd1-b0d3-4928-ad7f-515c613ad04c', 'sambastudio_endpoint_id': '3ef938b5-b1d6-4814-8086-cfe38e90bf0b', 'sambastudio_api_key': '6db47fcf-bdd0-48d6-b4b1-0bc7d0df823d', 'model_kwargs': {'select_expert': 'Meta-Llama-3-8B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512}}\n",
      "conf: ('EVAL_LLAMA370B', {'name': 'EVAL_LLAMA370B', 'model_kwargs': {'select_expert': 'Meta-Llama-3-70B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512}})\n",
      "llm_name: EVAL_LLAMA370B\n",
      "llm_config: {'sambastudio_base_url': 'https://sjc3-svqa.sambanova.net', 'sambastudio_project_id': '0c027dd1-b0d3-4928-ad7f-515c613ad04c', 'sambastudio_endpoint_id': '3ef938b5-b1d6-4814-8086-cfe38e90bf0b', 'sambastudio_api_key': '6db47fcf-bdd0-48d6-b4b1-0bc7d0df823d', 'model_kwargs': {'select_expert': 'Meta-Llama-3-70B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512}}\n",
      "eval_llms: [('EVAL_LLAMA38B', SambaStudio(sambastudio_base_url='https://sjc3-svqa.sambanova.net', sambastudio_project_id='0c027dd1-b0d3-4928-ad7f-515c613ad04c', sambastudio_endpoint_id='3ef938b5-b1d6-4814-8086-cfe38e90bf0b', sambastudio_api_key='6db47fcf-bdd0-48d6-b4b1-0bc7d0df823d', model_kwargs={'select_expert': 'Meta-Llama-3-8B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512})), ('EVAL_LLAMA370B', SambaStudio(sambastudio_base_url='https://sjc3-svqa.sambanova.net', sambastudio_project_id='0c027dd1-b0d3-4928-ad7f-515c613ad04c', sambastudio_endpoint_id='3ef938b5-b1d6-4814-8086-cfe38e90bf0b', sambastudio_api_key='6db47fcf-bdd0-48d6-b4b1-0bc7d0df823d', model_kwargs={'select_expert': 'Meta-Llama-3-70B-Instruct', 'process_prompt': False, 'max_tokens_to_generate': 512}))]\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Create evaluator\n",
    "eval_llms = []\n",
    "for conf in config.eval_llm_configs:\n",
    "    print(\"conf:\", conf)\n",
    "    llm_name, llm_config = config.get_llm_config(conf)\n",
    "    print(\"llm_name:\", llm_name)\n",
    "    print(\"llm_config:\", llm_config)\n",
    "    eval_llm = SambaStudio(**llm_config)\n",
    "    eval_llms.append((llm_name, eval_llm))\n",
    "\n",
    "print(\"eval_llms:\", eval_llms)\n",
    "\n",
    "eval_embeddings = HuggingFaceInstructEmbeddings(model_name=config.embedding_model_name)\n",
    "evaluator = RAGEvaluator(eval_llms, eval_embeddings, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 1: CSV file with pre-generated answers, no context\n",
    "eval_df = pd.read_csv(\"../data/res.csv\")\n",
    "results1 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 1:\", results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 2: CSV file with pre-generated answers and context\n",
    "eval_df = pd.read_csv(\"eval_set_with_answers_and_context.csv\")\n",
    "results2 = evaluator.evaluate(eval_df)\n",
    "print(\"Results 2:\", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kwasia/.pyenv/versions/3.11.3/envs/adi-rag-eval/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SambaStudio' object has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m eval_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/res.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m pipelines \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     load_pipeline(SambaStudio(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mllm_config), config)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, llm_config \u001b[38;5;129;01min\u001b[39;00m [config\u001b[38;5;241m.\u001b[39mget_llm_config(conf) \u001b[38;5;28;01mfor\u001b[39;00m conf \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mllm_configs]\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0m results3 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipelines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults 3:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results3)\n",
      "File \u001b[0;32m~/Documents/Projects/ai-starter-kit/utils/eval/rag_eval.py:191\u001b[0m, in \u001b[0;36mRAGEvaluator.evaluate\u001b[0;34m(self, eval_df, answer_generation_pipelines)\u001b[0m\n\u001b[1;32m    188\u001b[0m             answer \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mgenerate(query)\n\u001b[1;32m    189\u001b[0m             answers\u001b[38;5;241m.\u001b[39mappend(answer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 191\u001b[0m         eval_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m answers\n\u001b[1;32m    193\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    194\u001b[0m     answer_relevancy,\n\u001b[1;32m    195\u001b[0m     answer_correctness,\n\u001b[1;32m    196\u001b[0m     answer_similarity,\n\u001b[1;32m    197\u001b[0m ]\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meval_dataset_context_col:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SambaStudio' object has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "# Use Case 3: CSV file without answers, generate with pipelines, no context\n",
    "eval_df = pd.read_csv(\"../data/res.csv\")\n",
    "pipelines = [\n",
    "    load_pipeline(SambaStudio(**llm_config), config)\n",
    "    for _, llm_config in [config.get_llm_config(conf) for conf in config.llm_configs]\n",
    "]\n",
    "results3 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 3:\", results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 4: CSV file without answers, generate with pipelines, with context from vector DB\n",
    "eval_df = pd.read_csv(\"eval_set.csv\")\n",
    "pipelines = [\n",
    "    load_pipeline(\n",
    "        SambaStudio(\n",
    "            sambastudio_base_url=conf[\"base_url\"],\n",
    "            sambastudio_project_id=conf[\"project_id\"],\n",
    "            sambastudio_endpoint_id=conf[\"endpoint_id\"],\n",
    "            sambastudio_api_key=conf[\"api_key\"],\n",
    "            **conf[\"model_kwargs\"]\n",
    "        ),\n",
    "        config,\n",
    "    )\n",
    "    for conf in config.llm_configs\n",
    "]\n",
    "results4 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 4:\", results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 5: Evaluate on HF dataset\n",
    "config.config[\"eval_dataset\"][\"hf_dataset_name\"] = \"squad_v2\"\n",
    "eval_df = load_eval_dataframe(config)\n",
    "pipelines = [\n",
    "    load_pipeline(\n",
    "        SambaStudio(\n",
    "            sambastudio_base_url=conf[\"base_url\"],\n",
    "            sambastudio_project_id=conf[\"project_id\"],\n",
    "            sambastudio_endpoint_id=conf[\"endpoint_id\"],\n",
    "            sambastudio_api_key=conf[\"api_key\"],\n",
    "            **conf[\"model_kwargs\"]\n",
    "        ),\n",
    "        config,\n",
    "    )\n",
    "    for conf in config.llm_configs\n",
    "]\n",
    "results5 = evaluator.evaluate(eval_df, pipelines)\n",
    "print(\"Results 5:\", results5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adi-rag-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
