{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "load_dotenv(\"../../export.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sambanova_endpoint import SambaNovaEndpoint\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser, CommaSeparatedListOutputParser, StructuredOutputParser, ResponseSchema\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from vectordb.vector_db import VectorDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"speaker1: fire paramedic thirty three what is the address of your emergency\\nspeaker2: ys sir I need to: I: uh hh I need an ambulance as soon as possible sir\\nspeaker1: Ok sir what's your address\\nspeaker2: Los Angeles speaker2ifornia\\nspeaker2: nine zero zero seven seven\\nspeaker1: 's it Carolwood\\nspeaker2: Carolwood Drive yes hh ∙hh\\nspeaker3: yes\\nspeaker3: xxx xxx xxx xxx xxx xxx xxx xxx\\nspeaker1: ok sir what's the phone number you are speaker2ling from\\nspeaker1: xxx ⌈xxx ⌉\\nspeaker2: ⌊sir⌋\\nspeaker1: and what's the problem exactly what happened\\nspeaker2: uh sir I have a- we have a: ∙hh a- a: gentleman here that needs h:elp\\nspeaker2: ↓and he's: not breathing here\\nspeacke2: ∙hhh he's not breathing and we need\\nspeacke2: we're pu- trying to pump him\\nspeacke2: but he's not ∙hhh he⌈'s not⌉\\nspeaker1: ⌊ o k⌋ey\\nspeacke2: yes sir\\nspeaker1: o key: how old is he\\nspeacke2: he's uh fifty years old sir\\nspeaker1: fifty o key ∙hh\\nspeaker1: he's unconscious he's not breathing\\nspeacke2: Ye:s he's not breathing sir\\nspeaker1: o key and he's not conscious either\\nspeaker1: he's n⌈ot breathing⌉\\nspeacke2: ⌊no he's not⌋ conscious sir\\nspeaker1: o ke:y ∙hhh\\nspeaker3: ey how 're you doing\\nspeaker1: allright\\nspeaker1: do you have him- what\\nspeaker1: is he on the floor\\nspeaker1: where's he at right now\\nspeacke2: he's on the bed sir he's on the ⌈bed⌉ \\nspeaker1: ⌊o ⌋ key let's get him on the floor\\nspeaker2: okau\\nspeaker1: o kay let's get him down to ⌈the fl⌉oor\\nspeaker2: ⌊xxx⌋\\nspeaker1: I'm gonna help you with cee pee are right now o ke:y\\nspeaker2: we need him ⁇we get an inu⁇ ⌈just\\nspeaker1: ⌊Yes we're already on our way there\\nspeaker1: what I what ⌈I'm⌉ do it\\nspeaker2: ⌊xxx ⌋\\nspeaker1: ⌈but I can⌉ to help you over the phone\\nspeaker2: ⌊ xxxxx ⌋\\nspeaker1: We're already on our way\\nspeaker1: ∙hh did anybody see him\\nspeaker2: Ye:s u- we have a personal doctor here with him sir ∙hh\\nspeaker1: oh you have ⌈a doc⌉tor there\\nspeaker2: ⌊ xxx ⌋\\nspeaker2: ye:hs\\nspeaker2: but he's not responding to anything to no ∙hh\\nspeaker2: no: he's not responding to the cee pee are or any⌈thing⌉\\nspeaker1: ⌊ xxx⌋ o:oh\\nspeaker1: oka:y\\nspeaker1: oh we're on our way the:re\\nspeaker1: if your guys: a' doing cee pee are and you're- are instructed by a doctor he has a higher authority than me\\nspeaker1: And ⌈he's⌉ there on the scene\\nspeaker2: ⌊ xxx ⌋\\nspeaker2: ∙hh o⌈key⌉\\nspeaker1: ⌊u:h⌋m\\nspeaker3: hhh\\nspeaker1: ⁇well it was⁇ did anybody witness what happened\\nspeaker2: uhm no just the doctor sir\\nspeaker2: The doctor's been the only one here\\nspeaker1: okay so the doctor see what happened\\nspeaker2: u:h uhm doctor did you see what happened sir\\nspeaker3: xxx xxx xxx xxx xxx xxx xxx xxx\\nspeaker2: in e- sir you just ∙hhh\\nspeaker2: uh- uhm if you can please uh ⌈u-\\nspeaker1: ⌊we we are on our way\\nspeaker1: we are on our way\\nspeaker1: I'm jus: I'm just pa:ssing these questions on to my- my paramedics who are on their way there sir\\nspeaker2: thank you sir ⌈⁇we're ready⁇⌉\\nspeaker1: ⌊ ⁎uh uh⁎ ⌋\\nspeaker2: he's pumping he's pumping his chest\\nspeaker2: but he's not responding to anything sir please\\nspeaker1: okay\\nspeaker1: okay\\nspeaker1: we are on our ⌈way⌉\\nspeaker2: ⌊xxx ⌋\\nspeaker1: we're we're we're we're less than a mile away and we will be there ↓shortly\\nspeaker2: thank you sir thank you\\nspeaker1: okay sir\\nspeaker1: speaker2l us ba⌈ck xxx⌉ you need any help\\nspeaker2: ⌊ xxx ⌋\\nspeaker1: thank you\\nspeaker2: yes sir\\nspeaker1: allright \", metadata={'source': '../data/conversations/transcription/911.txt'})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../data/conversations/transcription\"\n",
    "conversations = os.listdir(path)\n",
    "documents = []\n",
    "for conversation in conversations:\n",
    "    conversation_path=os.path.join(path, conversation)\n",
    "    loader = TextLoader(conversation_path)\n",
    "    documents.extend(loader.load())\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition\n",
    "model = SambaNovaEndpoint(\n",
    "            model_kwargs={\n",
    "                \"do_sample\": True, \n",
    "                \"temperature\": 0.01,\n",
    "                \"max_tokens_to_generate\": 1500,\n",
    "            }\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sumarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic prompt example\n",
    "basic_summarization_prompt = load_prompt(\"../prompts/basic_sumarization.yaml\")\n",
    "\n",
    "#sumarization_prompt\n",
    "summarization_prompt=load_prompt(\"../prompts/summarization.yaml\")\n",
    "\n",
    "#brief sumarization prompt\n",
    "brief_summarization_prompt=load_prompt(\"../prompts/short_summary.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_summarization_chain = basic_summarization_prompt | model | output_parser\n",
    "summarization_chain = summarization_prompt | model | output_parser\n",
    "brief_summarization_chain = brief_summarization_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "input_variables={\"conversation\":documents[0].page_content}\n",
    "basic_summarization_response = basic_summarization_chain.invoke(input_variables)\n",
    "summarization_response = summarization_chain.invoke(input_variables)\n",
    "brief_summarization_response = brief_summarization_chain.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic sumarization ---\n",
      "\n",
      "A call between a fire paramedic and a person in need of emergency services. The person is requesting an ambulance and reports that a man is not breathing and unconscious. The paramedic asks for the address, which is provided as Carolwood Drive in Los Angeles, and the phone number the person is calling from. The paramedic also asks about the man's age and condition, and the person reports that the man is 50 years old and not responding to CPR. The paramedic informs the person that they are on their way and asks if anyone witnessed what happened. The person reports that only a doctor was present and that they are ready for the paramedics to arrive. The paramedic confirms that they are less than a mile away and will be there shortly.\n",
      "\n",
      "\n",
      "---  summarization ---\n",
      "\n",
      "A call was made to the fire department's emergency number, reporting an unconscious and unresponsive person who was not breathing. The caller provided the address of the emergency, which was in Los Angeles, and mentioned that a doctor was present and attempting CPR. The fire department dispatcher asked for additional information, such as the age of the person and their current location, and informed the caller that they were sending paramedics to the scene. The dispatcher also instructed the caller to move the person to the floor and to continue CPR until the paramedics arrived. The caller thanked the dispatcher and the conversation ended.\n",
      "\n",
      "\n",
      "---  brief summarization ---\n",
      "\n",
      "A call was made to the fire department's emergency number, reporting an unconscious and unresponsive person who was not breathing. The caller provided the address, which was in Los Angeles, and mentioned that a doctor was present but unable to revive the person. The fire department dispatcher asked questions to assess the situation and confirmed that the person was on the bed, not the floor. The dispatcher instructed the caller to move the person to the floor and began sending paramedics to the scene. The caller mentioned that the doctor had a higher authority than the dispatcher, and the dispatcher acknowledged this while still trying to help over the phone. The conversation ended with the dispatcher informing the caller that the paramedics were on their way and would be there shortly.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic sumarization ---\")\n",
    "print(basic_summarization_response)\n",
    "print(\"\\n\\n---  summarization ---\")\n",
    "print(summarization_response)\n",
    "print(\"\\n\\n---  brief summarization ---\")\n",
    "print(brief_summarization_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example custom output parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MainTopic(BaseModel):\n",
    "    main_topic_classes: str = Field(description=\"main topic class of the conversartion\")\n",
    "\n",
    "    # custom validation logic\n",
    "    @validator(\"main_topic_classes\")\n",
    "    def topic_in_topic_list(cls, field):\n",
    "        if field in [\"healt emergecy\", \"fire emergency\", \"terrorism emergency\"]:\n",
    "            raise ValueError(\"not a topic in the classes list\")\n",
    "        return field\n",
    "\n",
    "main_topic_classifcation_output_parser = PydanticOutputParser(pydantic_object=MainTopic)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= \"\"\"<s>[INST] <<SYS>>given the folowing conversation:\n",
    "\\n\n",
    "{conversation}.\n",
    "\\n\n",
    "clasify it in one of the following main topic classes:\n",
    "\\n\n",
    "{topic_classes}\n",
    "\\n\n",
    "{format_instructions}\n",
    "\\n\n",
    "<</SYS>>/n\n",
    "[/INST]\n",
    "\"\"\",\n",
    "    input_variables=[\"conversation\", \"topic_classes\"],\n",
    "    partial_variables={\"format_instructions\":main_topic_classifcation_output_parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main topic clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main prompt example\n",
    "basic_topic_classifcation_prompt = load_prompt(\"../prompts/basic_topic_classification.yaml\")\n",
    "\n",
    "#topic classification prompt\n",
    "topic_classification_prompt=load_prompt(\"../prompts/topic_classifications.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser = CommaSeparatedListOutputParser()\n",
    "list_output_parser.schema\n",
    "list_format_instructions = list_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chains\n",
    "basic_topic_classifcation_chain = basic_topic_classifcation_prompt | model | output_parser\n",
    "#topic_classifcation_chain = topic_classification_prompt | model | main_topic_classifcation_output_parser\n",
    "topic_classifcation_chain = topic_classification_prompt | model | list_output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "topic_classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]\n",
    "#topic_classes = []\n",
    "input_variables={\"conversation\":documents[0].page_content, \"topic_classes\" : \"\\n\\t- \".join(topic_classes), \"format_instructions\": list_format_instructions}\n",
    "\n",
    "basic_topic_classifcation_response = basic_topic_classifcation_chain.invoke(input_variables)\n",
    "topic_classifcation_response = topic_classifcation_chain.invoke(input_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic topic classification ---\n",
      "\n",
      "The main topic of this conversation is:\n",
      "\n",
      "* Emergency medical services\n",
      "\n",
      "The conversation is between a fire paramedic and a person who is requesting an ambulance for a medical emergency. The paramedic asks for information about the location, the patient's condition, and the situation, and the person on the phone provides the necessary details. The paramedic assures the person that they are on their way and offers additional instructions and reassurance.\n",
      "\n",
      "\n",
      "--- topic classification ---\n",
      "['Medical emergency', 'undefined']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic topic classification ---\")\n",
    "print(basic_topic_classifcation_response)\n",
    "print(\"\\n\\n--- topic classification ---\")\n",
    "print(topic_classifcation_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER prompt\n",
    "basic_ner_prompt=load_prompt(\"../prompts/basic_ner.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_ner_chain = basic_ner_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "input_variables={\"conversation\":documents[0].page_content, \"entities\" : \"\\n\\t- \".join(entities)}\n",
    "\n",
    "basic_ner_response = basic_ner_chain.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Basic NER ---\n",
      "\n",
      "City: Los Angeles\n",
      "Address: Carolwood Drive, 90077\n",
      "Customer Name: (not provided)\n",
      "Payment Type: (not provided)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- Basic NER ---\")\n",
    "print(basic_ner_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output parser \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "\n",
    "response_schemas = []\n",
    "\n",
    "for entity in entities:\n",
    "    response_schemas.append(ResponseSchema(name=entity, description=f\"{entity}s find in conversation\", type=\"list\"))\n",
    "\n",
    "entities_output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "\n",
    "#print(entities_output_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_prompt = PromptTemplate(\n",
    "#     template= \"\"\"<s>[INST] <<SYS>> Given the following conversation\n",
    "#           {conversation}\n",
    "#           extract th following named entities\n",
    "#           {entities}\n",
    "#           if there is not a given value for one entity in the list keep it blank\n",
    "          \n",
    "#           {format_instructions}\n",
    "#           <</SYS>>/n\n",
    "#           NER: [/INST]\n",
    "# \"\"\",\n",
    "#     input_variables=[\"conversation\", \"entities\"],\n",
    "#     partial_variables={\"format_instructions\":entities_output_parser.get_format_instructions()}\n",
    "# )\n",
    "\n",
    "ner_prompt = load_prompt(\"../prompts/ner.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_chain = ner_prompt | model | entities_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables={\"conversation\":documents[0].page_content,\n",
    "                 \"entities\" : \"\\n\\t- \".join(entities), \n",
    "                 \"format_instructions\":entities_output_parser.get_format_instructions()\n",
    "                 }\n",
    "\n",
    "ner_response = ner_chain.invoke(input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- NER ---\n",
      "<class 'dict'>\n",
      "{'city': ['Los Angeles'], 'address': ['Carolwood Drive'], 'customer_name': [], 'payment_type': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- NER ---\")\n",
    "print(type(ner_response))\n",
    "print(ner_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_sentiment_analysis_prompt = load_prompt(\"../prompts/basic_sentiment_analysis.yaml\")\n",
    "sentiment_analysis_prompt = load_prompt(\"../prompts/sentiment_analysis.yaml\")\n",
    "sentiment_analysis_prompt2 = load_prompt(\"../prompts/sentiment_analysis2.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_sentiment_analysis_chain = basic_sentiment_analysis_prompt | model | output_parser\n",
    "sentiment_analysis_chain = sentiment_analysis_prompt | model | output_parser\n",
    "sentiment_analysis_chain2 = sentiment_analysis_prompt2 | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "input_variables={\"conversation\":documents[0].page_content}\n",
    "basic_sentiment_analysis_response = basic_sentiment_analysis_chain.invoke(input_variables)\n",
    "sentiment_analysis_response = sentiment_analysis_chain.invoke(input_variables)\n",
    "sentiment_analysis_response2 = sentiment_analysis_chain2.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic sentiment analysis ---\n",
      "\n",
      "The overall customer's mood throughout the call can be described as \"urgent\". The customer is in a state of emergency and is seeking immediate assistance for a person who is not breathing and unconscious. The customer is anxious and concerned for the person's well-being and is trying to provide as much information as possible to the dispatcher to ensure that help arrives as quickly as possible. The customer's urgency and concern are evident in their tone and language throughout the call.\n",
      "\n",
      "\n",
      "---  sentiment analysis ---\n",
      "\n",
      "Negative\n",
      "\n",
      "\n",
      "---  sentiment analysis 2 ---\n",
      "panicked\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic sentiment analysis ---\")\n",
    "print(basic_sentiment_analysis_response)\n",
    "print(\"\\n\\n---  sentiment analysis ---\")\n",
    "print(sentiment_analysis_response)\n",
    "print(\"\\n\\n---  sentiment analysis 2 ---\")\n",
    "print(sentiment_analysis_response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factual Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 16:12:36,988 [INFO] - Total 1 files loaded\n",
      "2024-02-16 16:12:36,988 [INFO] - Total 1 chunks created\n",
      "2024-02-16 16:12:36,989 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 16:12:40,293 [INFO] - Use pytorch device: cpu\n",
      "2024-02-16 16:12:40,294 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 16:12:40,698 [INFO] - Vector store saved to None\n"
     ]
    }
   ],
   "source": [
    "# facts bdv  creation \n",
    "vdb=VectorDb()\n",
    "imput_path=\"../data/facts\"\n",
    "retriever = vdb.create_vdb(imput_path,1500,200,\"faiss\",None).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output parser \n",
    "\n",
    "factual_accuracy_analysis_response_schemas = [ResponseSchema(name=\"correct\", description=\"wether or not the provided information is correct\", type=\"bool\"),\n",
    "                                              ResponseSchema(name=\"errors\", description=\"list of summarized errors made by the agent, if there is no errors, emplty list\" , type=\"list\")\n",
    "                                              ]\n",
    "\n",
    "factual_accuracy_analysis_output_parser = StructuredOutputParser.from_response_schemas(factual_accuracy_analysis_response_schemas)\n",
    "\n",
    "format_instructions=factual_accuracy_analysis_output_parser.get_format_instructions()\n",
    "#print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chat_prompt = load_prompt(\"../prompts/factual_accuracy_analysis.yaml\")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    model, retrieval_qa_chat_prompt\n",
    ")\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "model_response=retrieval_chain.invoke({\"input\": documents[0].page_content, \"format_instructions\":format_instructions})[\"answer\"]\n",
    "\n",
    "factual_accuracy_analysis_response=factual_accuracy_analysis_output_parser.invoke(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  factual accuracy analysis ---\n",
      "<class 'dict'>\n",
      "{'correct': False, 'errors': ['Agent provided medical instructions, which is not allowed', 'Agent did not instruct the user to go to the nearest hospital']}\n"
     ]
    }
   ],
   "source": [
    "print(\"---  factual accuracy analysis ---\")\n",
    "print(type(factual_accuracy_analysis_response))\n",
    "print(factual_accuracy_analysis_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sumarization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(conversation, model=model):\n",
    "    summarization_prompt=load_prompt(\"../prompts/summarization.yaml\")\n",
    "    output_parser = StrOutputParser()\n",
    "    summarization_chain = summarization_prompt | model | output_parser\n",
    "    input_variables={\"conversation\": conversation}\n",
    "    print(\"summarizing\")\n",
    "    summarization_response = summarization_chain.invoke(input_variables)\n",
    "    print(\"summarizing done\")\n",
    "    return summarization_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main topic clasiffication method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_main_topic(conversation, classes, model=model):\n",
    "    topic_classification_prompt=load_prompt(\"../prompts/topic_classifications.yaml\")\n",
    "    list_output_parser = CommaSeparatedListOutputParser()\n",
    "    list_format_instructions = list_output_parser.get_format_instructions()\n",
    "    topic_classifcation_chain = topic_classification_prompt | model | list_output_parser\n",
    "    input_variables={\"conversation\":conversation, \"topic_classes\" : \"\\n\\t- \".join(classes), \"format_instructions\": list_format_instructions}\n",
    "    print(\"cassification\")\n",
    "    topic_classifcation_response = topic_classifcation_chain.invoke(input_variables)\n",
    "    print(\"classification done\")\n",
    "    return topic_classifcation_response\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## named entity recognition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_entities(conversation, entities, model=model):\n",
    "    ner_prompt = load_prompt(\"../prompts/ner.yaml\")\n",
    "    response_schemas = []\n",
    "    for entity in entities:\n",
    "        response_schemas.append(ResponseSchema(name=entity, description=f\"{entity}s find in conversation\", type=\"list\"))\n",
    "    entities_output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    ner_chain = ner_prompt | model | entities_output_parser\n",
    "    input_variables={\"conversation\":conversation,\n",
    "                     \"entities\" : \"\\n\\t- \".join(entities), \n",
    "                     \"format_instructions\":entities_output_parser.get_format_instructions()\n",
    "                    }\n",
    "    print(\"extracting entities\")\n",
    "    ner_response = ner_chain.invoke(input_variables)\n",
    "    print(\"extracting entities done\")\n",
    "    return ner_response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment(conversation, model=model):\n",
    "    sentiment_analysis_prompt = load_prompt(\"../prompts/sentiment_analysis2.yaml\")\n",
    "    output_parser = StrOutputParser()\n",
    "    sentiment_analysis_chain = sentiment_analysis_prompt | model | output_parser\n",
    "    input_variables={\"conversation\":conversation}\n",
    "    print(\"sentiment analysis\")\n",
    "    sentiment_analysis_response = sentiment_analysis_chain.invoke(input_variables)\n",
    "    print(\"sentiment analysis done\")\n",
    "    return sentiment_analysis_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factual check method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_retriever(documents_path):\n",
    "    vdb=VectorDb()\n",
    "    retriever = vdb.create_vdb(documents_path,1500,200,\"faiss\",None).as_retriever()\n",
    "    return retriever\n",
    "\n",
    "def factual_accuracy_analysis(conversation, retriever, model=model):\n",
    "    factual_accuracy_analysis_response_schemas = [ResponseSchema(name=\"correct\",\n",
    "                                                                 description=\"wether or not the provided information is correct\",\n",
    "                                                                 type=\"bool\"\n",
    "                                                                 ),\n",
    "                                                  ResponseSchema(name=\"errors\",\n",
    "                                                                 description=\"list of summarized errors made by the agent, if there is no errors, emplty list\" ,\n",
    "                                                                 type=\"list\")\n",
    "                                                ]\n",
    "    factual_accuracy_analysis_output_parser = StructuredOutputParser.from_response_schemas(factual_accuracy_analysis_response_schemas)\n",
    "    format_instructions=factual_accuracy_analysis_output_parser.get_format_instructions()\n",
    "    retrieval_qa_chat_prompt = load_prompt(\"../prompts/factual_accuracy_analysis.yaml\")\n",
    "    combine_docs_chain = create_stuff_documents_chain(\n",
    "        model, retrieval_qa_chat_prompt\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "    input_variables={\"input\":conversation,\n",
    "                     \"format_instructions\":format_instructions\n",
    "                    }\n",
    "    model_response=retrieval_chain.invoke(input_variables)[\"answer\"]\n",
    "    print(\"factual check\")\n",
    "    factual_accuracy_analysis_response=factual_accuracy_analysis_output_parser.invoke(model_response)\n",
    "    print(\"factual check done\")\n",
    "    return factual_accuracy_analysis_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"speaker1: fire paramedic thirty three what is the address of your emergency\\nspeaker2: ys sir I need to: I: uh hh I need an ambulance as soon as possible sir\\nspeaker1: Ok sir what's your address\\nspeaker2: Los Angeles speaker2ifornia\\nspeaker2: nine zero zero seven seven\\nspeaker1: 's it Carolwood\\nspeaker2: Carolwood Drive yes hh ∙hh\\nspeaker3: yes\\nspeaker3: xxx xxx xxx xxx xxx xxx xxx xxx\\nspeaker1: ok sir what's the phone number you are speaker2ling from\\nspeaker1: xxx ⌈xxx ⌉\\nspeaker2: ⌊sir⌋\\nspeaker1: and what's the problem exactly what happened\\nspeaker2: uh sir I have a- we have a: ∙hh a- a: gentleman here that needs h:elp\\nspeaker2: ↓and he's: not breathing here\\nspeacke2: ∙hhh he's not breathing and we need\\nspeacke2: we're pu- trying to pump him\\nspeacke2: but he's not ∙hhh he⌈'s not⌉\\nspeaker1: ⌊ o k⌋ey\\nspeacke2: yes sir\\nspeaker1: o key: how old is he\\nspeacke2: he's uh fifty years old sir\\nspeaker1: fifty o key ∙hh\\nspeaker1: he's unconscious he's not breathing\\nspeacke2: Ye:s he's not breathing sir\\nspeaker1: o key and he's not conscious either\\nspeaker1: he's n⌈ot breathing⌉\\nspeacke2: ⌊no he's not⌋ conscious sir\\nspeaker1: o ke:y ∙hhh\\nspeaker3: ey how 're you doing\\nspeaker1: allright\\nspeaker1: do you have him- what\\nspeaker1: is he on the floor\\nspeaker1: where's he at right now\\nspeacke2: he's on the bed sir he's on the ⌈bed⌉ \\nspeaker1: ⌊o ⌋ key let's get him on the floor\\nspeaker2: okau\\nspeaker1: o kay let's get him down to ⌈the fl⌉oor\\nspeaker2: ⌊xxx⌋\\nspeaker1: I'm gonna help you with cee pee are right now o ke:y\\nspeaker2: we need him ⁇we get an inu⁇ ⌈just\\nspeaker1: ⌊Yes we're already on our way there\\nspeaker1: what I what ⌈I'm⌉ do it\\nspeaker2: ⌊xxx ⌋\\nspeaker1: ⌈but I can⌉ to help you over the phone\\nspeaker2: ⌊ xxxxx ⌋\\nspeaker1: We're already on our way\\nspeaker1: ∙hh did anybody see him\\nspeaker2: Ye:s u- we have a personal doctor here with him sir ∙hh\\nspeaker1: oh you have ⌈a doc⌉tor there\\nspeaker2: ⌊ xxx ⌋\\nspeaker2: ye:hs\\nspeaker2: but he's not responding to anything to no ∙hh\\nspeaker2: no: he's not responding to the cee pee are or any⌈thing⌉\\nspeaker1: ⌊ xxx⌋ o:oh\\nspeaker1: oka:y\\nspeaker1: oh we're on our way the:re\\nspeaker1: if your guys: a' doing cee pee are and you're- are instructed by a doctor he has a higher authority than me\\nspeaker1: And ⌈he's⌉ there on the scene\\nspeaker2: ⌊ xxx ⌋\\nspeaker2: ∙hh o⌈key⌉\\nspeaker1: ⌊u:h⌋m\\nspeaker3: hhh\\nspeaker1: ⁇well it was⁇ did anybody witness what happened\\nspeaker2: uhm no just the doctor sir\\nspeaker2: The doctor's been the only one here\\nspeaker1: okay so the doctor see what happened\\nspeaker2: u:h uhm doctor did you see what happened sir\\nspeaker3: xxx xxx xxx xxx xxx xxx xxx xxx\\nspeaker2: in e- sir you just ∙hhh\\nspeaker2: uh- uhm if you can please uh ⌈u-\\nspeaker1: ⌊we we are on our way\\nspeaker1: we are on our way\\nspeaker1: I'm jus: I'm just pa:ssing these questions on to my- my paramedics who are on their way there sir\\nspeaker2: thank you sir ⌈⁇we're ready⁇⌉\\nspeaker1: ⌊ ⁎uh uh⁎ ⌋\\nspeaker2: he's pumping he's pumping his chest\\nspeaker2: but he's not responding to anything sir please\\nspeaker1: okay\\nspeaker1: okay\\nspeaker1: we are on our ⌈way⌉\\nspeaker2: ⌊xxx ⌋\\nspeaker1: we're we're we're we're less than a mile away and we will be there ↓shortly\\nspeaker2: thank you sir thank you\\nspeaker1: okay sir\\nspeaker1: speaker2l us ba⌈ck xxx⌉ you need any help\\nspeaker2: ⌊ xxx ⌋\\nspeaker1: thank you\\nspeaker2: yes sir\\nspeaker1: allright \", metadata={'source': '../data/conversations/transcription/911.txt'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../data/conversations/transcription\"\n",
    "conversations = os.listdir(path)\n",
    "documents = []\n",
    "for conversation in conversations:\n",
    "    conversation_path=os.path.join(path, conversation)\n",
    "    loader = TextLoader(conversation_path)\n",
    "    documents.extend(loader.load())\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:12:43,126 [INFO] - Total 1 files loaded\n",
      "2024-02-19 17:12:43,127 [INFO] - Total 1 chunks created\n",
      "2024-02-19 17:12:43,128 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:12:45,547 [INFO] - Use pytorch device: cpu\n",
      "2024-02-19 17:12:45,548 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:12:46,070 [INFO] - Vector store saved to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarizing\n",
      "summarizing done\n",
      "cassification\n",
      "classification done\n",
      "extracting entities\n",
      "extracting entities done\n",
      "sentiment analysis\n",
      "sentiment analysis done\n",
      "factual check\n",
      "factual check done\n",
      "{'classification': ['Medical emergency', 'undefined'],\n",
      " 'entities': {'address': ['Carolwood Drive'],\n",
      "              'city': ['Los Angeles'],\n",
      "              'customer_name': [],\n",
      "              'payment_type': []},\n",
      " 'factual_analysis': {'correct': False,\n",
      "                      'errors': ['Agent provided medical instructions, which '\n",
      "                                 'is not allowed',\n",
      "                                 'Agent did not instruct the user to go to the '\n",
      "                                 'nearest hospital']},\n",
      " 'quality_score': None,\n",
      " 'sentiment': 'panicked',\n",
      " 'summary': '\\n'\n",
      "            \"A call was made to the fire department's emergency number, \"\n",
      "            'reporting an unconscious and unresponsive person who was not '\n",
      "            'breathing. The caller provided the address of the emergency, '\n",
      "            'which was in Los Angeles, and mentioned that a doctor was present '\n",
      "            'and attempting CPR. The fire department dispatcher asked for '\n",
      "            'additional information, such as the age of the person and their '\n",
      "            'current location, and informed the caller that they were sending '\n",
      "            'paramedics to the scene. The dispatcher also instructed the '\n",
      "            'caller to move the person to the floor and to continue CPR until '\n",
      "            'the paramedics arrived. The caller thanked the dispatcher and the '\n",
      "            'conversation ended.'}\n"
     ]
    }
   ],
   "source": [
    "def call_analysis(conversation, documents_path, classes_list, entities_list):\n",
    "    retriever = set_retriever(documents_path)\n",
    "    summary = get_summary(conversation)\n",
    "    classification = classify_main_topic(conversation, classes_list)\n",
    "    entities = get_entities(conversation, entities_list)\n",
    "    sentiment = get_sentiment(conversation)\n",
    "    factual_analysis = factual_accuracy_analysis(conversation, retriever)\n",
    "    quality_score = None \n",
    "    \n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"classification\": classification,\n",
    "        \"entities\": entities,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"factual_analysis\": factual_analysis,\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "\n",
    "classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]   \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "pprint(call_analysis(conversation=documents[0].page_content, documents_path=\"../data/facts\", classes_list=classes, entities_list=entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting entitiessentiment analysis\n",
      "summarizing\n",
      "\n",
      "cassification\n",
      "model called\n",
      "model called\n",
      "model called\n",
      "model called\n",
      "classification done\n",
      "summarizing done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:20:08,280 [INFO] - Total 1 files loaded\n",
      "2024-02-19 17:20:08,281 [INFO] - Total 1 chunks created\n",
      "/Users/jorgep/Documents/PostCallAnaysis/pca_env/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n",
      "2024-02-19 17:20:09,381 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:20:11,561 [INFO] - Use pytorch device: cpu\n",
      "2024-02-19 17:20:11,562 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 17:20:11,925 [INFO] - Loading faiss.\n",
      "2024-02-19 17:20:11,951 [INFO] - Successfully loaded faiss.\n",
      "2024-02-19 17:20:11,957 [INFO] - Vector store saved to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model called\n",
      "extracting entities done\n",
      "sentiment analysis done\n",
      "factual check\n",
      "factual check done\n",
      "{'classification': ['Medical emergency', 'undefined'],\n",
      " 'entities': {'address': ['Carolwood Drive'],\n",
      "              'city': ['Los Angeles'],\n",
      "              'customer_name': [],\n",
      "              'payment_type': []},\n",
      " 'factual_analysis': {'correct': False,\n",
      "                      'errors': ['Agent provided medical instructions, which '\n",
      "                                 'is not allowed',\n",
      "                                 'Agent did not instruct the user to go to the '\n",
      "                                 'nearest hospital']},\n",
      " 'quality_score': None,\n",
      " 'sentiment': 'panicked',\n",
      " 'summary': '\\n'\n",
      "            \"A call was made to the fire department's emergency number, \"\n",
      "            'reporting an unconscious and unresponsive person who was not '\n",
      "            'breathing. The caller provided the address of the emergency, '\n",
      "            'which was in Los Angeles, and mentioned that a doctor was present '\n",
      "            'and attempting CPR. The fire department dispatcher asked for '\n",
      "            'additional information, such as the age of the person and their '\n",
      "            'current location, and informed the caller that they were sending '\n",
      "            'paramedics to the scene. The dispatcher also instructed the '\n",
      "            'caller to move the person to the floor and to continue CPR until '\n",
      "            'the paramedics arrived. The caller thanked the dispatcher and the '\n",
      "            'conversation ended.'}\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def call_analysis_parallel(conversation, documents_path, classes_list, entities_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submitting tasks to executor\n",
    "        retriever_future = executor.submit(set_retriever, documents_path=documents_path)\n",
    "        summary_future = executor.submit(get_summary, conversation=conversation)\n",
    "        classification_future = executor.submit(classify_main_topic, conversation=conversation, classes=classes)\n",
    "        entities_future = executor.submit(get_entities, conversation=conversation, entities=entities_list)\n",
    "        sentiment_future = executor.submit(get_sentiment, conversation=conversation)\n",
    "        retriever=retriever_future.result()\n",
    "        factual_analysis_future = executor.submit(factual_accuracy_analysis, conversation=conversation, retriever = retriever)\n",
    "\n",
    "        # Retrieving results\n",
    "        summary = summary_future.result()\n",
    "        classification = classification_future.result()\n",
    "        entities = entities_future.result()\n",
    "        sentiment = sentiment_future.result()\n",
    "        factual_analysis = factual_analysis_future.result()\n",
    "\n",
    "    quality_score = None  # Assuming this doesn't require parallel execution\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"classification\": classification,\n",
    "        \"entities\": entities,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"factual_analysis\": factual_analysis,\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]   \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "pprint(call_analysis_parallel(conversation=documents[0].page_content, documents_path=\"../data/facts\", classes_list=classes, entities_list=entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
