{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\")\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "load_dotenv(\"../../export.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sambanova_endpoint import SambaNovaEndpoint\n",
    "from langchain.prompts import PromptTemplate, load_prompt\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser, CommaSeparatedListOutputParser, StructuredOutputParser, ResponseSchema\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from vectordb.vector_db import VectorDb\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import ReduceDocumentsChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='start_time,end_time,speaker,text\\n0,2.5,SPEAKER_01,Our Primeti 33. What is yet as emergency?\\n3,11.9,SPEAKER_00,\"Yes, sir, I need to, uh, uh. I need an ambulance as soon as possible, sir. Los Angeles, California. 9 007. 7.\"\\n11,12.3,SPEAKER_01,A car.\\n13,14.7,SPEAKER_00,Carol Wood Drive. Yes.\\n14,14.6,SPEAKER_01,\\n15,16.6,SPEAKER_00,\"Yeah, a.\"\\n17,21.4,SPEAKER_01,\"Okay, sir. What\\'s the phone number you calling from? A cer. And what\\'s the of exactly what happened.\"\\n22,31.6,SPEAKER_00,\"Uh, sir. Oh, I have a we have a a gentleman here that needs help, and he\\'s not breathing yet. He\\'s not breeding, and we need to We\\'re trying to pump him, but he\\'s not he\\'s not.\"\\n32,37.2,SPEAKER_01,\"Okay, how does. He\\'s a 50 years old. Ser 50. Okay, he\\'s unconscious. He\\'s not reading.\"\\n38,39.5,SPEAKER_00,\"Yes, he\\'s not breathing, sir.\"\\n40,53.0,SPEAKER_01,\"Okay, and he\\'s not conscious either. Don\\'t conscious. Okay, all right, you have him on. Is he on the floor? Where is he? Out right now. He\\'s on the bet, sir. He\\'s on the. Okay, let\\'s get him on the floor, okay? okay, let\\'s get him down to Orm. I hope you\\'ll see P. R. right now. Okay.\"\\n56,58.0,SPEAKER_00,We need them. You get when you just party on.\\n57,62.9,SPEAKER_01,Just you on way there? We\\'re on Wemo. But I kind of help you over the phone. We are you on our way? Do you buy? See him.\\n63,71.9,SPEAKER_00,\"Yes, we have a personal doctor if you\\'re with him, sir. Oh, you have a doctor there? Yes, but he\\'s not responding to anything to. No, no, he\\'s not responding to C P R or anything, so.\"\\n72,82.4,SPEAKER_01,\"Oh, okay, well, we\\'re on our way there. If your guys doing Sempron, You\\'re instructed by doctor s r authority than me Any think they\\'re on se? Um, we an was anybody witness what happened.\"\\n84,87.3,SPEAKER_00,\"Uh, no, just a doctor. So the doctor\\'s been the only one here.\"\\n87,88.7,SPEAKER_01,\"Okay, so did doctor see what happen.\"\\n89,96.7,SPEAKER_00,\"Uh, um, Doctor, did you see what happens there? And sure, you just, uh, um, if you can please, uh, ren away.\"\\n96,100.4,SPEAKER_01,\"Okay, we\\'re in a way. I\\'m just I\\'m just passing these questions on the my, uh, parametic s by their on way there, sir.\"\\n101,105.5,SPEAKER_00,\"A your, uh. he\\'s pumping. He\\'s pumping his chest, but he\\'s not responding to anything except please.\"\\n105,114.6,SPEAKER_01,\"Okay, okay, we on. We les than a mile away. Thank you, sir, thank you, yes.\"\\n', metadata={'source': '../data/conversations/transcription/911_transcript.csv'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"../data/conversations/transcription\"\n",
    "conversations = os.listdir(path)\n",
    "documents = []\n",
    "for conversation in conversations:\n",
    "    conversation_path=os.path.join(path, conversation)\n",
    "    loader = TextLoader(conversation_path)\n",
    "    documents.extend(loader.load())\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition\n",
    "model = SambaNovaEndpoint(\n",
    "            model_kwargs={\n",
    "                \"do_sample\": True, \n",
    "                \"temperature\": 0.01,\n",
    "                \"max_tokens_to_generate\": 1500,\n",
    "            }\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sumarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic prompt example\n",
    "basic_summarization_prompt = load_prompt(\"../prompts/basic_sumarization.yaml\")\n",
    "\n",
    "#sumarization_prompt\n",
    "summarization_prompt=load_prompt(\"../prompts/summarization.yaml\")\n",
    "\n",
    "#brief sumarization prompt\n",
    "brief_summarization_prompt=load_prompt(\"../prompts/short_summary.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_summarization_chain = basic_summarization_prompt | model | output_parser\n",
    "summarization_chain = summarization_prompt | model | output_parser\n",
    "brief_summarization_chain = brief_summarization_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "input_variables={\"conversation\":documents[0].page_content}\n",
    "basic_summarization_response = basic_summarization_chain.invoke(input_variables)\n",
    "summarization_response = summarization_chain.invoke(input_variables)\n",
    "brief_summarization_response = brief_summarization_chain.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic sumarization ---\n",
      "\n",
      "A call between a fire paramedic and a person in need of emergency services. The person is requesting an ambulance and reports that a man is not breathing and unconscious. The paramedic asks for the address, which is provided as Carolwood Drive in Los Angeles, and the phone number the person is calling from. The paramedic also asks about the man's age and condition, and the person reports that the man is 50 years old and not responding to CPR. The paramedic informs the person that they are on their way and asks if anyone witnessed what happened. The person reports that only a doctor was present and that they are ready for the paramedics to arrive. The paramedic confirms that they are less than a mile away and will be there shortly.\n",
      "\n",
      "\n",
      "---  summarization ---\n",
      "\n",
      "A call was made to the fire department's emergency number, reporting an unconscious and unresponsive person who was not breathing. The caller provided the address of the emergency, which was in Los Angeles, and mentioned that a doctor was present and attempting CPR. The fire department dispatcher asked for additional information, such as the age of the person and their current location, and informed the caller that they were sending paramedics to the scene. The dispatcher also instructed the caller to move the person to the floor and to continue CPR until the paramedics arrived. The caller thanked the dispatcher and the conversation ended.\n",
      "\n",
      "\n",
      "---  brief summarization ---\n",
      "\n",
      "A call was made to the fire department's emergency number, reporting an unconscious and unresponsive person who was not breathing. The caller provided the address, which was in Los Angeles, and mentioned that a doctor was present but unable to revive the person. The fire department dispatcher asked questions to assess the situation and confirmed that the person was on the bed, not the floor. The dispatcher instructed the caller to move the person to the floor and began sending paramedics to the scene. The caller mentioned that the doctor had a higher authority than the dispatcher, and the dispatcher acknowledged this while still trying to help over the phone. The conversation ended with the dispatcher informing the caller that the paramedics were on their way and would be there shortly.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic sumarization ---\")\n",
    "print(basic_summarization_response)\n",
    "print(\"\\n\\n---  summarization ---\")\n",
    "print(summarization_response)\n",
    "print(\"\\n\\n---  brief summarization ---\")\n",
    "print(brief_summarization_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce long calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduce_prompt = load_prompt(\"../prompts/reduce2.yaml\")\n",
    "reduce_chain = LLMChain(llm=model, prompt=reduce_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split long document\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size= 800, chunk_overlap= 200)\n",
    "chunks = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=1200,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='start_time,end_time,speaker,text\\n0,2.5,SPEAKER_01,Our Primeti 33. What is yet as emergency?\\n3,11.9,SPEAKER_00,\"Yes, sir, I need to, uh, uh. I need an ambulance as soon as possible, sir. Los Angeles, California. 9 007. 7.\"\\n11,12.3,SPEAKER_01,A car.\\n13,14.7,SPEAKER_00,Carol Wood Drive. Yes.\\n14,14.6,SPEAKER_01,\\n15,16.6,SPEAKER_00,\"Yeah, a.\"\\n17,21.4,SPEAKER_01,\"Okay, sir. What\\'s the phone number you calling from? A cer. And what\\'s the of exactly what happened.\"\\n22,31.6,SPEAKER_00,\"Uh, sir. Oh, I have a we have a a gentleman here that needs help, and he\\'s not breathing yet. He\\'s not breeding, and we need to We\\'re trying to pump him, but he\\'s not he\\'s not.\"\\n32,37.2,SPEAKER_01,\"Okay, how does. He\\'s a 50 years old. Ser 50. Okay, he\\'s unconscious. He\\'s not reading.\"', metadata={'source': '../data/conversations/transcription/911_transcript.csv'}),\n",
       "  Document(page_content='32,37.2,SPEAKER_01,\"Okay, how does. He\\'s a 50 years old. Ser 50. Okay, he\\'s unconscious. He\\'s not reading.\"\\n38,39.5,SPEAKER_00,\"Yes, he\\'s not breathing, sir.\"\\n40,53.0,SPEAKER_01,\"Okay, and he\\'s not conscious either. Don\\'t conscious. Okay, all right, you have him on. Is he on the floor? Where is he? Out right now. He\\'s on the bet, sir. He\\'s on the. Okay, let\\'s get him on the floor, okay? okay, let\\'s get him down to Orm. I hope you\\'ll see P. R. right now. Okay.\"\\n56,58.0,SPEAKER_00,We need them. You get when you just party on.\\n57,62.9,SPEAKER_01,Just you on way there? We\\'re on Wemo. But I kind of help you over the phone. We are you on our way? Do you buy? See him.', metadata={'source': '../data/conversations/transcription/911_transcript.csv'}),\n",
       "  Document(page_content='57,62.9,SPEAKER_01,Just you on way there? We\\'re on Wemo. But I kind of help you over the phone. We are you on our way? Do you buy? See him.\\n63,71.9,SPEAKER_00,\"Yes, we have a personal doctor if you\\'re with him, sir. Oh, you have a doctor there? Yes, but he\\'s not responding to anything to. No, no, he\\'s not responding to C P R or anything, so.\"\\n72,82.4,SPEAKER_01,\"Oh, okay, well, we\\'re on our way there. If your guys doing Sempron, You\\'re instructed by doctor s r authority than me Any think they\\'re on se? Um, we an was anybody witness what happened.\"\\n84,87.3,SPEAKER_00,\"Uh, no, just a doctor. So the doctor\\'s been the only one here.\"\\n87,88.7,SPEAKER_01,\"Okay, so did doctor see what happen.\"', metadata={'source': '../data/conversations/transcription/911_transcript.csv'}),\n",
       "  Document(page_content='84,87.3,SPEAKER_00,\"Uh, no, just a doctor. So the doctor\\'s been the only one here.\"\\n87,88.7,SPEAKER_01,\"Okay, so did doctor see what happen.\"\\n89,96.7,SPEAKER_00,\"Uh, um, Doctor, did you see what happens there? And sure, you just, uh, um, if you can please, uh, ren away.\"\\n96,100.4,SPEAKER_01,\"Okay, we\\'re in a way. I\\'m just I\\'m just passing these questions on the my, uh, parametic s by their on way there, sir.\"\\n101,105.5,SPEAKER_00,\"A your, uh. he\\'s pumping. He\\'s pumping his chest, but he\\'s not responding to anything except please.\"\\n105,114.6,SPEAKER_01,\"Okay, okay, we on. We les than a mile away. Thank you, sir, thank you, yes.\"', metadata={'source': '../data/conversations/transcription/911_transcript.csv'})],\n",
       " 'output_text': \"\\nSPEAKER_01: What's the emergency?\\n\\nSPEAKER_00: We need an ambulance in Los Angeles, California, 90077. A car is involved.\\n\\nSPEAKER_01: Okay, what's the phone number you're calling from?\\n\\nSPEAKER_00: (provides phone number)\\n\\nSPEAKER_01: Okay, what's the situation?\\n\\nSPEAKER_00: We have a gentleman who's not breathing and not responding. He's unconscious.\\n\\nSPEAKER_01: Okay, how old is he?\\n\\nSPEAKER_00: He's 50 years old.\\n\\nSPEAKER_01: Okay, we're on our way. Is he on the floor?\\n\\nSPEAKER_00: Yes, he's on the floor.\\n\\nSPEAKER_01: Okay, let's get him on the floor, okay? Let's get him down to Orm. I hope you'll see P.R. right now. Okay.\\n\\nSPEAKER_00: We need them.\\n\\nSPEAKER_01: We're on our way. Do you buy? See him.\\n\\nSPEAKER_00: Yes, we have a personal doctor here.\\n\\nSPEAKER_01: Okay, we're on our way there. If your guys doing CPR, you're instructed by doctor's authority. Did the doctor see what happened?\\n\\nSPEAKER_00: No, just the doctor.\\n\\nSPEAKER_01: Okay, so did the doctor see what happened?\\n\\nSPEAKER_00: Uh, no, just a doctor.\\n\\nSPEAKER_01: Okay, we're in a way. I'm just passing these questions on to my paramedics. They're on their way there, sir.\\n\\nSPEAKER_00: He's pumping. He's pumping his chest, but he's not responding to anything except please.\\n\\nSPEAKER_01: Okay, okay, we're less than a mile away. Thank you, sir, thank you.\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_documents_chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example custom output parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MainTopic(BaseModel):\n",
    "    main_topic_classes: str = Field(description=\"main topic class of the conversartion\")\n",
    "\n",
    "    # custom validation logic\n",
    "    @validator(\"main_topic_classes\")\n",
    "    def topic_in_topic_list(cls, field):\n",
    "        if field in [\"healt emergecy\", \"fire emergency\", \"terrorism emergency\"]:\n",
    "            raise ValueError(\"not a topic in the classes list\")\n",
    "        return field\n",
    "\n",
    "main_topic_classifcation_output_parser = PydanticOutputParser(pydantic_object=MainTopic)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= \"\"\"<s>[INST] <<SYS>>given the folowing conversation:\n",
    "\\n\n",
    "{conversation}.\n",
    "\\n\n",
    "clasify it in one of the following main topic classes:\n",
    "\\n\n",
    "{topic_classes}\n",
    "\\n\n",
    "{format_instructions}\n",
    "\\n\n",
    "<</SYS>>/n\n",
    "[/INST]\n",
    "\"\"\",\n",
    "    input_variables=[\"conversation\", \"topic_classes\"],\n",
    "    partial_variables={\"format_instructions\":main_topic_classifcation_output_parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main topic clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main prompt example\n",
    "basic_topic_classifcation_prompt = load_prompt(\"../prompts/basic_topic_classification.yaml\")\n",
    "\n",
    "#topic classification prompt\n",
    "topic_classification_prompt=load_prompt(\"../prompts/topic_classifications.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser = CommaSeparatedListOutputParser()\n",
    "list_output_parser.schema\n",
    "list_format_instructions = list_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chains\n",
    "basic_topic_classifcation_chain = basic_topic_classifcation_prompt | model | output_parser\n",
    "#topic_classifcation_chain = topic_classification_prompt | model | main_topic_classifcation_output_parser\n",
    "topic_classifcation_chain = topic_classification_prompt | model | list_output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "topic_classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]\n",
    "#topic_classes = []\n",
    "input_variables={\"conversation\":documents[0].page_content, \"topic_classes\" : \"\\n\\t- \".join(topic_classes), \"format_instructions\": list_format_instructions}\n",
    "\n",
    "basic_topic_classifcation_response = basic_topic_classifcation_chain.invoke(input_variables)\n",
    "topic_classifcation_response = topic_classifcation_chain.invoke(input_variables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic topic classification ---\n",
      "\n",
      "The main topic of this conversation is:\n",
      "\n",
      "* Emergency medical services\n",
      "\n",
      "The conversation is between a fire paramedic and a person who is requesting an ambulance for a medical emergency. The paramedic asks for information about the location, the patient's condition, and the situation, and the person on the phone provides the necessary details. The paramedic assures the person that they are on their way and offers additional instructions and reassurance.\n",
      "\n",
      "\n",
      "--- topic classification ---\n",
      "['Medical emergency', 'undefined']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic topic classification ---\")\n",
    "print(basic_topic_classifcation_response)\n",
    "print(\"\\n\\n--- topic classification ---\")\n",
    "print(topic_classifcation_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER prompt\n",
    "basic_ner_prompt=load_prompt(\"../prompts/basic_ner.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_ner_chain = basic_ner_prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "input_variables={\"conversation\":documents[0].page_content, \"entities\" : \"\\n\\t- \".join(entities)}\n",
    "\n",
    "basic_ner_response = basic_ner_chain.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Basic NER ---\n",
      "\n",
      "City: Los Angeles\n",
      "Address: Carolwood Drive, 90077\n",
      "Customer Name: (not provided)\n",
      "Payment Type: (not provided)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- Basic NER ---\")\n",
    "print(basic_ner_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output parser \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "\n",
    "response_schemas = []\n",
    "\n",
    "for entity in entities:\n",
    "    response_schemas.append(ResponseSchema(name=entity, description=f\"{entity}s find in conversation\", type=\"list\"))\n",
    "\n",
    "entities_output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "\n",
    "#print(entities_output_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_prompt = PromptTemplate(\n",
    "#     template= \"\"\"<s>[INST] <<SYS>> Given the following conversation\n",
    "#           {conversation}\n",
    "#           extract th following named entities\n",
    "#           {entities}\n",
    "#           if there is not a given value for one entity in the list keep it blank\n",
    "          \n",
    "#           {format_instructions}\n",
    "#           <</SYS>>/n\n",
    "#           NER: [/INST]\n",
    "# \"\"\",\n",
    "#     input_variables=[\"conversation\", \"entities\"],\n",
    "#     partial_variables={\"format_instructions\":entities_output_parser.get_format_instructions()}\n",
    "# )\n",
    "\n",
    "ner_prompt = load_prompt(\"../prompts/ner.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_chain = ner_prompt | model | entities_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables={\"conversation\":documents[0].page_content,\n",
    "                 \"entities\" : \"\\n\\t- \".join(entities), \n",
    "                 \"format_instructions\":entities_output_parser.get_format_instructions()\n",
    "                 }\n",
    "\n",
    "ner_response = ner_chain.invoke(input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- NER ---\n",
      "<class 'dict'>\n",
      "{'city': ['Los Angeles'], 'address': ['Carolwood Drive'], 'customer_name': [], 'payment_type': []}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- NER ---\")\n",
    "print(type(ner_response))\n",
    "print(ner_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_sentiment_analysis_prompt = load_prompt(\"../prompts/basic_sentiment_analysis.yaml\")\n",
    "sentiment_analysis_prompt = load_prompt(\"../prompts/sentiment_analysis.yaml\")\n",
    "sentiment_analysis_prompt2 = load_prompt(\"../prompts/sentiment_analysis2.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic output parser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_sentiment_analysis_chain = basic_sentiment_analysis_prompt | model | output_parser\n",
    "sentiment_analysis_chain = sentiment_analysis_prompt | model | output_parser\n",
    "sentiment_analysis_chain2 = sentiment_analysis_prompt2 | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke chains\n",
    "input_variables={\"conversation\":documents[0].page_content}\n",
    "basic_sentiment_analysis_response = basic_sentiment_analysis_chain.invoke(input_variables)\n",
    "sentiment_analysis_response = sentiment_analysis_chain.invoke(input_variables)\n",
    "sentiment_analysis_response2 = sentiment_analysis_chain2.invoke(input_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---  basic sentiment analysis ---\n",
      "\n",
      "The overall customer's mood throughout the call can be described as \"urgent\". The customer is in a state of emergency and is seeking immediate assistance for a person who is not breathing and unconscious. The customer is anxious and concerned for the person's well-being and is trying to provide as much information as possible to the dispatcher to ensure that help arrives as quickly as possible. The customer's urgency and concern are evident in their tone and language throughout the call.\n",
      "\n",
      "\n",
      "---  sentiment analysis ---\n",
      "\n",
      "Negative\n",
      "\n",
      "\n",
      "---  sentiment analysis 2 ---\n",
      "panicked\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n---  basic sentiment analysis ---\")\n",
    "print(basic_sentiment_analysis_response)\n",
    "print(\"\\n\\n---  sentiment analysis ---\")\n",
    "print(sentiment_analysis_response)\n",
    "print(\"\\n\\n---  sentiment analysis 2 ---\")\n",
    "print(sentiment_analysis_response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factual Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:17:18,940 [INFO] - Total 1 files loaded\n",
      "2024-02-27 19:17:18,941 [INFO] - Splitter: splitting documents\n",
      "2024-02-27 19:17:18,941 [INFO] - Total 1 chunks created\n",
      "2024-02-27 19:17:18,942 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:17:22,599 [INFO] - Use pytorch device: cpu\n",
      "2024-02-27 19:17:22,600 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:17:23,006 [INFO] - Vector store saved to None\n"
     ]
    }
   ],
   "source": [
    "# facts bdv  creation \n",
    "vdb=VectorDb()\n",
    "imput_path=\"../data/documents\"\n",
    "retriever = vdb.create_vdb(imput_path,1500,200,\"faiss\",None).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output parser \n",
    "\n",
    "factual_accuracy_analysis_response_schemas = [ResponseSchema(name=\"correct\", description=\"wether or not the provided information is correct\", type=\"bool\"),\n",
    "                                              ResponseSchema(name=\"errors\", description=\"list of summarized errors made by the agent, if there is no errors, emplty list\" , type=\"list\")\n",
    "                                              ]\n",
    "\n",
    "factual_accuracy_analysis_output_parser = StructuredOutputParser.from_response_schemas(factual_accuracy_analysis_response_schemas)\n",
    "\n",
    "format_instructions=factual_accuracy_analysis_output_parser.get_format_instructions()\n",
    "#print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chat_prompt = load_prompt(\"../prompts/factual_accuracy_analysis.yaml\")\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    model, retrieval_qa_chat_prompt\n",
    ")\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "model_response=retrieval_chain.invoke({\"input\": documents[0].page_content, \"format_instructions\":format_instructions})[\"answer\"]\n",
    "\n",
    "factual_accuracy_analysis_response=factual_accuracy_analysis_output_parser.invoke(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  factual accuracy analysis ---\n",
      "<class 'dict'>\n",
      "{'correct': False, 'errors': ['Agent provided medical instructions, which is not appropriate for an emergency call agent.']}\n"
     ]
    }
   ],
   "source": [
    "print(\"---  factual accuracy analysis ---\")\n",
    "print(type(factual_accuracy_analysis_response))\n",
    "print(factual_accuracy_analysis_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_chunks(documents):\n",
    "    #split long document\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size= 800, chunk_overlap= 200)\n",
    "    return  splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce call method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_call(documents):\n",
    "    reduce_prompt = load_prompt(\"../prompts/reduce.yaml\")\n",
    "    \n",
    "    reduce_chain = LLMChain(llm=model, prompt=reduce_prompt)  \n",
    "     \n",
    "    combine_documents_chain = StuffDocumentsChain(\n",
    "        llm_chain=reduce_chain, document_variable_name=\"transcription_chunks\"\n",
    "    )\n",
    "\n",
    "    # Combines and iteravely reduces the mapped documents\n",
    "    reduce_documents_chain = ReduceDocumentsChain(\n",
    "        # This is final chain that is called.\n",
    "        combine_documents_chain=combine_documents_chain,\n",
    "        # If documents exceed context for `StuffDocumentsChain`\n",
    "        collapse_documents_chain=combine_documents_chain,\n",
    "        # The maximum number of tokens to group documents into.\n",
    "        token_max=1200,  \n",
    "    )\n",
    "    \n",
    "    new_document = reduce_documents_chain.invoke(documents)[\"output_text\"]\n",
    "    \n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sumarization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(conversation, model=model):\n",
    "    summarization_prompt=load_prompt(\"../prompts/summarization.yaml\")\n",
    "    output_parser = StrOutputParser()\n",
    "    summarization_chain = summarization_prompt | model | output_parser\n",
    "    input_variables={\"conversation\": conversation}\n",
    "    print(\"summarizing\")\n",
    "    summarization_response = summarization_chain.invoke(input_variables)\n",
    "    print(\"summarizing done\")\n",
    "    return summarization_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main topic clasiffication method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_main_topic(conversation, classes, model=model):\n",
    "    topic_classification_prompt=load_prompt(\"../prompts/topic_classifications.yaml\")\n",
    "    list_output_parser = CommaSeparatedListOutputParser()\n",
    "    list_format_instructions = list_output_parser.get_format_instructions()\n",
    "    topic_classifcation_chain = topic_classification_prompt | model | list_output_parser\n",
    "    input_variables={\"conversation\":conversation, \"topic_classes\" : \"\\n\\t- \".join(classes), \"format_instructions\": list_format_instructions}\n",
    "    print(\"cassification\")\n",
    "    topic_classifcation_response = topic_classifcation_chain.invoke(input_variables)\n",
    "    print(\"classification done\")\n",
    "    return topic_classifcation_response\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## named entity recognition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_entities(conversation, entities, model=model):\n",
    "    ner_prompt = load_prompt(\"../prompts/ner.yaml\")\n",
    "    response_schemas = []\n",
    "    for entity in entities:\n",
    "        response_schemas.append(ResponseSchema(name=entity, description=f\"{entity}s find in conversation\", type=\"list\"))\n",
    "    entities_output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    ner_chain = ner_prompt | model | entities_output_parser\n",
    "    input_variables={\"conversation\":conversation,\n",
    "                     \"entities\" : \"\\n\\t- \".join(entities), \n",
    "                     \"format_instructions\":entities_output_parser.get_format_instructions()\n",
    "                    }\n",
    "    print(\"extracting entities\")\n",
    "    ner_response = ner_chain.invoke(input_variables)\n",
    "    print(\"extracting entities done\")\n",
    "    return ner_response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment(conversation, model=model):\n",
    "    sentiment_analysis_prompt = load_prompt(\"../prompts/sentiment_analysis2.yaml\")\n",
    "    output_parser = StrOutputParser()\n",
    "    sentiment_analysis_chain = sentiment_analysis_prompt | model | output_parser\n",
    "    input_variables={\"conversation\":conversation}\n",
    "    print(\"sentiment analysis\")\n",
    "    sentiment_analysis_response = sentiment_analysis_chain.invoke(input_variables)\n",
    "    print(\"sentiment analysis done\")\n",
    "    return sentiment_analysis_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## factual check method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_retriever(documents_path):\n",
    "    vdb=VectorDb()\n",
    "    retriever = vdb.create_vdb(documents_path,1500,200,\"faiss\",None).as_retriever()\n",
    "    return retriever\n",
    "\n",
    "def factual_accuracy_analysis(conversation, retriever, model=model):\n",
    "    factual_accuracy_analysis_response_schemas = [ResponseSchema(name=\"correct\",\n",
    "                                                                 description=\"wether or not the provided information is correct\",\n",
    "                                                                 type=\"bool\"\n",
    "                                                                 ),\n",
    "                                                  ResponseSchema(name=\"errors\",\n",
    "                                                                 description=\"list of summarized errors made by the agent, if there is no errors, emplty list\" ,\n",
    "                                                                 type=\"list\"),\n",
    "                                                  ResponseSchema(name=\"score\",\n",
    "                                                                 description=\"puntuation from 1 to 100 of the overall quallity of the agent\" ,\n",
    "                                                                 type=\"int\")\n",
    "                                                ]\n",
    "    factual_accuracy_analysis_output_parser = StructuredOutputParser.from_response_schemas(factual_accuracy_analysis_response_schemas)\n",
    "    format_instructions=factual_accuracy_analysis_output_parser.get_format_instructions()\n",
    "    retrieval_qa_chat_prompt = load_prompt(\"../prompts/factual_accuracy_analysis_scoring.yaml\")\n",
    "    combine_docs_chain = create_stuff_documents_chain(\n",
    "        model, retrieval_qa_chat_prompt\n",
    "    )\n",
    "    retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
    "    input_variables={\"input\":conversation,\n",
    "                     \"format_instructions\":format_instructions\n",
    "                    }\n",
    "    print(\"factual check\")\n",
    "    model_response=retrieval_chain.invoke(input_variables)[\"answer\"]\n",
    "    factual_accuracy_analysis_response=factual_accuracy_analysis_output_parser.invoke(model_response)\n",
    "    print(\"factual check done\")\n",
    "    return factual_accuracy_analysis_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/conversations/transcription\"\n",
    "conversations = os.listdir(path)\n",
    "documents = []\n",
    "for conversation in conversations:\n",
    "    conversation_path=os.path.join(path, conversation)\n",
    "    loader = TextLoader(conversation_path)\n",
    "    documents.extend(loader.load())\n",
    "documents\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size= 800, chunk_overlap= 200)\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:01:56,748 [INFO] - Total 1 files loaded\n",
      "2024-02-28 10:01:56,750 [INFO] - Splitter: splitting documents\n",
      "2024-02-28 10:01:56,751 [INFO] - Total 1 chunks created\n",
      "2024-02-28 10:01:56,753 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:01:59,365 [INFO] - Use pytorch device: cpu\n",
      "2024-02-28 10:01:59,366 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 10:01:59,808 [INFO] - Vector store saved to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarizing\n",
      "summarizing done\n",
      "cassification\n",
      "classification done\n",
      "extracting entities\n",
      "extracting entities done\n",
      "sentiment analysis\n",
      "sentiment analysis done\n",
      "factual check\n",
      "factual check done\n",
      "{'classification': ['Medical emergency', 'undefined'],\n",
      " 'entities': {'address': ['90077'],\n",
      "              'city': ['Los Angeles'],\n",
      "              'customer_name': [],\n",
      "              'payment_type': []},\n",
      " 'factual_analysis': {'correct': True, 'errors': [], 'score': 100},\n",
      " 'quality_score': None,\n",
      " 'sentiment': 'urgent',\n",
      " 'summary': '\\n'\n",
      "            'A call was made to emergency services requesting an ambulance in '\n",
      "            'Los Angeles, California, 90077, as a man was reported unconscious '\n",
      "            'and not breathing. The caller provided their phone number and '\n",
      "            'location, and the emergency operator asked for additional '\n",
      "            \"information, such as the man's age (50) and whether he was on the \"\n",
      "            'floor (yes). The operator informed the caller that an ambulance '\n",
      "            'was on the way and asked if the man was receiving CPR. The caller '\n",
      "            'replied that a personal doctor was present and performing CPR. '\n",
      "            'The operator assured the caller that the paramedics were on their '\n",
      "            \"way and would be instructed by the doctor's authority. The caller \"\n",
      "            \"mentioned that the doctor was pumping the man's chest, but he was \"\n",
      "            'not responding except for pleading sounds. The operator thanked '\n",
      "            'the caller and informed them that the ambulance was less than a '\n",
      "            'mile away.'}\n"
     ]
    }
   ],
   "source": [
    "def call_analysis(conversation, documents_path, classes_list, entities_list):\n",
    "    reduced_conversation = reduce_call(conversation)\n",
    "    retriever = set_retriever(documents_path)\n",
    "    summary = get_summary(reduced_conversation)\n",
    "    classification = classify_main_topic(reduced_conversation, classes_list)\n",
    "    entities = get_entities(reduced_conversation, entities_list)\n",
    "    sentiment = get_sentiment(reduced_conversation)\n",
    "    factual_analysis = factual_accuracy_analysis(reduced_conversation, retriever)\n",
    "    quality_score = factual_analysis[\"score\"] \n",
    "    \n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"classification\": classification,\n",
    "        \"entities\": entities,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"factual_analysis\": factual_analysis,\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "\n",
    "classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]   \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "conversation_chunks = get_chunks(documents)\n",
    "pprint(call_analysis(conversation=conversation_chunks, documents_path=\"../data/documents\", classes_list=classes, entities_list=entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:27:59,770 [INFO] - Total 1 files loaded\n",
      "2024-02-27 19:27:59,771 [INFO] - Splitter: splitting documents\n",
      "2024-02-27 19:27:59,772 [INFO] - Total 1 chunks created\n",
      "2024-02-27 19:27:59,772 [INFO] - Load pretrained SentenceTransformer: hkunlp/instructor-large\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cassificationsummarizing\n",
      "\n",
      "extracting entities\n",
      "sentiment analysis\n",
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:28:02,348 [INFO] - Use pytorch device: cpu\n",
      "2024-02-27 19:28:02,349 [INFO] - Processing embeddings using hkunlp/instructor-large. This could take time depending on the number of chunks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 19:28:02,761 [INFO] - Vector store saved to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factual check\n",
      "extracting entities done\n",
      "summarizing done\n",
      "sentiment analysis done\n",
      "classification done\n",
      "factual check done\n",
      "{'classification': ['Medical emergency', 'undefined'],\n",
      " 'entities': {'address': ['90077'],\n",
      "              'city': ['Los Angeles'],\n",
      "              'customer_name': [],\n",
      "              'payment_type': []},\n",
      " 'factual_analysis': {'correct': False,\n",
      "                      'errors': ['Agent provided medical instructions, which '\n",
      "                                 'is not appropriate for an emergency call '\n",
      "                                 'agent.',\n",
      "                                 'Agent instructed the user to go to the '\n",
      "                                 'nearest hospital, which is not the correct '\n",
      "                                 'protocol for a medical emergency.']},\n",
      " 'quality_score': 82,\n",
      " 'sentiment': 'urgent',\n",
      " 'summary': '\\n'\n",
      "            'A call was made to emergency services requesting an ambulance in '\n",
      "            'Los Angeles, California, 90077, as a man was reported unconscious '\n",
      "            'and not breathing. The caller provided their phone number and '\n",
      "            'location, and the emergency operator asked for additional '\n",
      "            \"information, such as the man's age (50) and whether he was on the \"\n",
      "            'floor (yes). The operator informed the caller that an ambulance '\n",
      "            'was on the way and asked if the man was receiving CPR. The caller '\n",
      "            'replied that a personal doctor was present and performing CPR. '\n",
      "            'The operator assured the caller that the paramedics were on their '\n",
      "            \"way and would be instructed by the doctor's authority. The caller \"\n",
      "            \"mentioned that the doctor was pumping the man's chest, but he was \"\n",
      "            'not responding except for pleading sounds. The operator thanked '\n",
      "            'the caller and informed them that the ambulance was less than a '\n",
      "            'mile away.'}\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def call_analysis_parallel(conversation, documents_path, classes_list, entities_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submitting tasks to executor\n",
    "        reduced_conversation = reduce_call(conversation)\n",
    "        retriever_future = executor.submit(set_retriever, documents_path=documents_path)\n",
    "        summary_future = executor.submit(get_summary, conversation=reduced_conversation)\n",
    "        classification_future = executor.submit(classify_main_topic, conversation=reduced_conversation, classes=classes_list)\n",
    "        entities_future = executor.submit(get_entities, conversation=reduced_conversation, entities=entities_list)\n",
    "        sentiment_future = executor.submit(get_sentiment, conversation=reduced_conversation)\n",
    "        retriever=retriever_future.result()\n",
    "        factual_analysis_future = executor.submit(factual_accuracy_analysis, conversation=reduced_conversation, retriever = retriever)\n",
    "\n",
    "        # Retrieving results\n",
    "        summary = summary_future.result()\n",
    "        classification = classification_future.result()\n",
    "        entities = entities_future.result()\n",
    "        sentiment = sentiment_future.result()\n",
    "        factual_analysis = factual_analysis_future.result()\n",
    "\n",
    "    quality_score = factual_analysis[\"score\"] # Assuming this doesn't require parallel execution\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"classification\": classification,\n",
    "        \"entities\": entities,\n",
    "        \"sentiment\": sentiment,\n",
    "        \"factual_analysis\": factual_analysis,\n",
    "        \"quality_score\": quality_score\n",
    "    }\n",
    "classes = [\"medical emergecy\", \"animals emergency\", \"terrorism emergency\", \"fire emergency\", \"undefined\"]   \n",
    "entities = [\"city\", \"address\", \"customer_name\", \"payment_type\"]\n",
    "pprint(call_analysis_parallel(conversation=chunks, documents_path=\"../data/documents\", classes_list=classes, entities_list=entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
